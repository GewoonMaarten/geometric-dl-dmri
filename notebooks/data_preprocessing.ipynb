{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing for MUDI data and Human Connectome Project (HCP). The goal of this notebook is to create a HDF5 file with the following structure:\n",
    " - `data`: contains all normalized voxel data and attributes to \"de'-normalize the data\n",
    " - `index`: a list of indexes to connect each voxel to a subject\n",
    " - `masks`: a list of integers to connect each voxel to a tissue type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from nilearn import image, plotting\n",
    "from nilearn.masking import apply_mask\n",
    "\n",
    "from autoencoder.logger import logger, set_log_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change these to your correct path**\n",
    "\n",
    "Make sure you have the following packages installed:\n",
    " - FSL: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUDI_PATH = Path(\"/media/maarten/disk1/MUDI/\")\n",
    "HCP_PATH = Path(\"/media/maarten/disk1/HCP_2\")\n",
    "\n",
    "MUDI_OUTPUT_PATH = Path(\"/media/maarten/disk1/MUDI\")\n",
    "HCP_OUTPUT_PATH = Path(\"/media/maarten/disk1/HCP_2\")\n",
    "\n",
    "FSL_INSTALL_PATH = \"/usr/local/fsl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FSLOUTPUTTYPE\"] = \"NIFTI_GZ\"\n",
    "os.environ[\"FSLDIR\"] = FSL_INSTALL_PATH\n",
    "os.environ[\"PATH\"] = f\"{FSL_INSTALL_PATH}/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Retrieving file paths\n",
    "\n",
    "We create a `dataclass` to store all the paths in. We can use these later to load the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MRISubjectData:\n",
    "    subject_name: str\n",
    "    subject_id: int\n",
    "    project: str  # Name of the dataset\n",
    "    output_file: Path\n",
    "\n",
    "    # paths\n",
    "    scheme_path: Path\n",
    "    root_path: Path  # path were all MRI data of the subject is located\n",
    "    dmri_path: Path  # relative to root_path\n",
    "    t1_path: Optional[Path] = None  # relative to root_path\n",
    "    t2_path: Optional[Path] = None  # relative to root_path\n",
    "    brain_mask_path: Optional[Path] = None  # relative to root_path\n",
    "    fivett_mask_path: Optional[Path] = None\n",
    "\n",
    "    # normalization data\n",
    "    max_data: Optional[float] = 1.0\n",
    "    lstq_coefficient: Optional[float] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_mudi_subjects: List[MRISubjectData] = list()\n",
    "mri_hcp_subjects: List[MRISubjectData] = list()\n",
    "\n",
    "# MUDI subjects\n",
    "for i in range(1, 6):\n",
    "    subject = f\"cdmri001{i}\"\n",
    "\n",
    "    # check if we have a previously generated 5tt mask\n",
    "    fivett_mask_path = None\n",
    "    if Path(MUDI_PATH, subject, \"5tt.nii\").exists():\n",
    "        fivett_mask_path = Path(MUDI_PATH, subject, \"5tt.nii\")\n",
    "\n",
    "    mri_mudi_subjects.append(\n",
    "        MRISubjectData(\n",
    "            subject,\n",
    "            10 + i,\n",
    "            \"MUDI\",\n",
    "            Path(MUDI_OUTPUT_PATH, f\"prj_MUDI_data.hdf5\"),\n",
    "            Path(MUDI_PATH, \"parameters_new.txt\"),\n",
    "            Path(MUDI_PATH, subject),\n",
    "            Path(\"MB_Re_t_moco_registered_applytopup.nii.gz\"),\n",
    "            brain_mask_path=Path(\"brain_mask.nii.gz\"),\n",
    "            # fivett_mask_path=fivett_mask_path,\n",
    "        )\n",
    "    )\n",
    "\n",
    "logger.info(f\"found {len(mri_mudi_subjects)} MUDI subjects\")\n",
    "\n",
    "# HCP subjects\n",
    "for subject_path in HCP_PATH.iterdir():\n",
    "    if not subject_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    subject = subject_path.name\n",
    "\n",
    "    if int(subject) in (\n",
    "        286347,\n",
    "        995174,\n",
    "        884064,\n",
    "        186040,\n",
    "        827052,\n",
    "        392750,\n",
    "        569965,\n",
    "        114116,\n",
    "        362034,\n",
    "        701535,\n",
    "        153934,\n",
    "        578057,\n",
    "        154330,\n",
    "        804646,\n",
    "        888678,\n",
    "        180533,\n",
    "        578158,\n",
    "        196851,\n",
    "        206727,\n",
    "    ):  # remove subjects with few bvecs\n",
    "        continue\n",
    "\n",
    "    # check if we have a previously generated 5tt mask\n",
    "    fivett_mask_path = None\n",
    "    if Path(HCP_PATH, subject, \"5tt.nii\").exists():\n",
    "        fivett_mask_path = Path(HCP_PATH, subject, \"5tt.nii\")\n",
    "\n",
    "    # load and combine all MRI parameters\n",
    "    scheme_path = Path(HCP_PATH, subject, f\"T1w/Diffusion/scheme.txt\")\n",
    "    if not scheme_path.exists():\n",
    "        bvals_path = Path(HCP_PATH, subject, \"T1w/Diffusion/bvals\")\n",
    "        bvecs_path = Path(HCP_PATH, subject, \"T1w/Diffusion/bvecs\")\n",
    "        bvals = np.loadtxt(bvals_path)[:, np.newaxis]\n",
    "        bvals = np.around(bvals, -3)\n",
    "        bvecs = np.loadtxt(bvecs_path).T\n",
    "        scheme = np.c_[bvecs, bvals]\n",
    "        np.savetxt(scheme_path, scheme, fmt=\"%.6f %.6f %.6f %d\")\n",
    "\n",
    "    mri_hcp_subjects.append(\n",
    "        MRISubjectData(\n",
    "            subject,\n",
    "            int(subject),\n",
    "            \"HCP\",\n",
    "            Path(HCP_OUTPUT_PATH, f\"prj_HCP_data.hdf5\"),\n",
    "            scheme_path,\n",
    "            Path(HCP_PATH, subject),\n",
    "            Path(\"T1w/Diffusion/data.nii.gz\"),\n",
    "            Path(\"T1w/T1w_acpc_dc_restore_1.25.nii.gz\"),\n",
    "            brain_mask_path=Path(\"T1w/Diffusion/nodif_brain_mask.nii.gz\"),\n",
    "            fivett_mask_path=fivett_mask_path,\n",
    "        )\n",
    "    )\n",
    "\n",
    "logger.info(f\"found {len(mri_hcp_subjects)} HCP subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCP has a lot of subject and training time might take too long if you want to use them all. This function select `n` random samples, evenly distributed between genders. Make sure `n` is an even number.\n",
    "\n",
    "**Note**: it requires that you download the \"Behavioral Data\" CSV from the \"WU-Minn HCP Data - 1200 Subjects\" dataset (https://db.humanconnectome.org). Rename it \"prj_HCP_metadata.csv\" and place it in the HCP download folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HCP_samples(n: int) -> List[int]:\n",
    "    df = pd.read_csv(Path(HCP_PATH, \"prj_HCP_metadata.csv\"), index_col=\"Subject\")\n",
    "\n",
    "    subject_ids = [s.subject_id for s in mri_hcp_subjects]\n",
    "    subject_dict = {s.subject_id: s for s in mri_hcp_subjects}\n",
    "\n",
    "    df = df.loc[subject_ids]\n",
    "    for selected_subject_id in list(df.groupby(by=\"Gender\").sample(n=n // 2).index):\n",
    "        yield subject_dict[selected_subject_id]\n",
    "\n",
    "\n",
    "mri_hcp_subjects = list(get_HCP_samples(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating and applying a brain mask\n",
    "Create a brain mask from dwi image if none was provided. Based on the script bet from FSL toolbox. Docs: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brain_mask(subject: MRISubjectData):\n",
    "    \"\"\"\"\"\"\n",
    "    logger.info(\"starting brain mask generation\")\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"bet\",\n",
    "            Path(subject.root_path, subject.dmri_path),\n",
    "            Path(subject.root_path, \"brain.nii\"),\n",
    "            \"-m\",\n",
    "            \"-n\",\n",
    "            \"-f\",\n",
    "            \"0.5\",\n",
    "        ]\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        subject.brain_mask_path = Path(subject.root_path, \"brain_mask.nii.gz\")\n",
    "    logger.info(\"finished brain mask generation, return code: %d\", result.returncode)\n",
    "    return result.returncode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the brain mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(subject: MRISubjectData) -> np.ndarray:\n",
    "    dmri_path = Path(subject.root_path, subject.dmri_path)\n",
    "    brain_mask_path = None\n",
    "    if subject.brain_mask_path:\n",
    "        brain_mask_path = Path(subject.root_path, subject.brain_mask_path)\n",
    "    else:\n",
    "        result_code = generate_brain_mask(subject)\n",
    "        if result_code != 0:\n",
    "            logger.error(\"could not generate brain mask\")\n",
    "            return\n",
    "        brain_mask_path = Path(subject.root_path, subject.brain_mask_path)\n",
    "    return np.transpose(apply_mask(imgs=str(dmri_path), mask_img=str(brain_mask_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_dmri_data(scan_data: np.ndarray, subject: MRISubjectData):\n",
    "    logger.info(\"storing data for subject %s\", subject.subject_name)\n",
    "\n",
    "    indexes = np.full((scan_data.shape[0],), subject.subject_id)\n",
    "\n",
    "    with h5py.File(subject.output_file, \"a\", libver=\"latest\") as archive:\n",
    "        if \"data\" in archive.keys():\n",
    "            archive[\"index\"].resize((archive[\"index\"].shape[0] + indexes.shape[0]), axis=0)\n",
    "            archive[\"index\"][-indexes.shape[0] :] = indexes\n",
    "\n",
    "            archive[\"data\"].resize((archive[\"data\"].shape[0] + scan_data.shape[0]), axis=0)\n",
    "            archive[\"data\"][-scan_data.shape[0] :] = scan_data\n",
    "            archive[\"data\"].attrs[\"max_data\"] = np.append(archive[\"data\"].attrs[\"max_data\"], [subject.max_data])\n",
    "            archive[\"data\"].attrs[\"lstsq_coefficient\"] = np.append(\n",
    "                archive[\"data\"].attrs[\"lstsq_coefficient\"], [subject.lstsq_coefficient]\n",
    "            )\n",
    "            archive[\"data\"].attrs[str(subject.subject_id)] = archive[\"data\"].attrs[\"max_data\"].shape[0] - 1\n",
    "        else:\n",
    "            archive.create_dataset(\"index\", data=indexes, chunks=(1024,), maxshape=(None,))\n",
    "            dataset = archive.create_dataset(\n",
    "                \"data\", data=scan_data, chunks=(1024, scan_data.shape[1]), maxshape=(None, scan_data.shape[1])\n",
    "            )\n",
    "            dataset.attrs[\"max_data\"] = np.array([subject.max_data])\n",
    "            dataset.attrs[\"lstsq_coefficient\"] = np.array([subject.lstsq_coefficient])\n",
    "            dataset.attrs[str(subject.subject_id)] = 0\n",
    "\n",
    "\n",
    "def normalize_data(subjects: List[MRISubjectData]):\n",
    "    scheme = np.loadtxt(subjects[0].scheme_path)\n",
    "    mask_b_0 = scheme[:, 3] == 0.0\n",
    "    subject_0 = subjects[0]\n",
    "\n",
    "    logger.info(\"normalizing subject %s (subject 0)\", subject_0.subject_name)\n",
    "\n",
    "    scan_data_subject_0 = load_scan(subject_0)\n",
    "\n",
    "    max_data = np.percentile(scan_data_subject_0, 95)\n",
    "    logger.info(\"95th percentile: %f\", max_data)\n",
    "    subject_0.max_data = max_data\n",
    "    subject_0.lstsq_coefficient = 1.0\n",
    "\n",
    "    scan_data_median_subject_0 = np.median(scan_data_subject_0[:, mask_b_0], axis=0)\n",
    "    scan_data_normalized = scan_data_subject_0.astype(\"float32\") / subject_0.max_data\n",
    "\n",
    "    store_dmri_data(scan_data_normalized, subject_0)\n",
    "\n",
    "    for subject in subjects[1:]:\n",
    "        logger.info(\"normalizing subject %s\", subject.subject_name)\n",
    "\n",
    "        # if subject.output_file.exists():\n",
    "        #     continue\n",
    "\n",
    "        scan_data = load_scan(subject)\n",
    "        median_scan = np.median(scan_data[:, mask_b_0], axis=0)\n",
    "\n",
    "        scan_lstsq_coef, _, _, _ = np.linalg.lstsq(median_scan[:, np.newaxis], scan_data_median_subject_0, rcond=-1)\n",
    "        logger.info(\"lstsq coefficient for subject %s: %f\", subject.subject_name, scan_lstsq_coef[0])\n",
    "\n",
    "        subject.lstsq_coefficient = scan_lstsq_coef[0]\n",
    "        subject.max_data = max_data\n",
    "\n",
    "        scan_data_normalized = scan_data.astype(\"float32\") * subject.lstsq_coefficient / subject.max_data\n",
    "\n",
    "        store_dmri_data(scan_data_normalized, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_data(mri_mudi_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_data(mri_hcp_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process bvecs and bvals and create scheme file\n",
    "Average b vectors and round b values to the nearest 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bvecs_bvals(subjects: List[MRISubjectData]):\n",
    "    bvecs = None\n",
    "    bvals = None\n",
    "    other = None\n",
    "\n",
    "    for subject in subjects:\n",
    "        scheme = np.loadtxt(subject.scheme_path)\n",
    "        if bvecs is not None:\n",
    "            bvecs += scheme[:, :3]\n",
    "        else:\n",
    "            bvecs = scheme[:, :3]\n",
    "            bvals = scheme[:, 3]\n",
    "            other = scheme[:, 4:]\n",
    "\n",
    "    bvals = np.around(bvals, -3)\n",
    "    bvecs /= len(subjects)\n",
    "\n",
    "    for i in range(bvecs.shape[0]):\n",
    "        if bvals[i] == 0.0:\n",
    "            bvecs[i] = 0.0\n",
    "        else:\n",
    "            bvecs[i] /= np.sqrt(np.sum(bvecs[i] ** 2))\n",
    "\n",
    "    return np.c_[bvecs, bvals, other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = process_bvecs_bvals(mri_mudi_subjects)\n",
    "np.savetxt(Path(MUDI_PATH, \"scheme.txt\"), scheme, fmt=\"%.6f %.6f %.6f %d %d %d\")\n",
    "with h5py.File(Path(MUDI_OUTPUT_PATH, \"prj_MUDI_parameters.hdf5\"), \"w\") as hdf5_f:\n",
    "    hdf5_f.create_dataset(\"parameters\", data=scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = process_bvecs_bvals(mri_hcp_subjects)\n",
    "np.savetxt(Path(HCP_PATH, \"parameters.txt\"), scheme, fmt=\"%.6f %.6f %.6f %d\")\n",
    "with h5py.File(Path(HCP_OUTPUT_PATH, \"prj_HCP_parameters.hdf5\"), \"w\") as hdf5_f:\n",
    "    hdf5_f.create_dataset(\"parameters\", data=scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate White matter, grey matter, etc, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_5tt_mask(subject: MRISubjectData):\n",
    "    \"\"\"Docs: https://mrtrix.readthedocs.io/en/latest/reference/commands/5ttgen.html#ttgen-fsl\"\"\"\n",
    "    logger.info(\"starting 5tt generation, this will take a few minutes...\")\n",
    "    output_path = Path(subject.root_path, \"5tt.nii\")\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"5ttgen\",\n",
    "            \"fsl\",\n",
    "            Path(subject.root_path, subject.t1_path),  # The input T1-weighted image\n",
    "            output_path,  # The output 5TT image\n",
    "            \"-mask\",\n",
    "            Path(subject.root_path, subject.brain_mask_path),\n",
    "            \"-force\",\n",
    "            \"-nocrop\",\n",
    "        ]\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        logger.error(\"could not finish generation, return code: %d\", result.returncode)\n",
    "        return\n",
    "\n",
    "    subject.fivett_mask_path = output_path\n",
    "    logger.info(\"finished 5tt generation, return code: %d\", result.returncode)\n",
    "    return result.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tt_masks_by_dwi(subject: MRISubjectData):\n",
    "    logger.info(\"starting 5tt generation, this will take a few minutes...\")\n",
    "    output_path = Path(subject.root_path, \"3tt.nii\")\n",
    "    # calculate reponse data\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"dwi2response\",\n",
    "            \"dhollander\",\n",
    "            Path(subject.root_path, subject.dmri_path),\n",
    "            Path(subject.root_path, \"wm_response.txt\"),\n",
    "            Path(subject.root_path, \"gm_response.txt\"),\n",
    "            Path(subject.root_path, \"csf_response.txt\"),\n",
    "            \"-grad\",\n",
    "            subject.scheme_path,\n",
    "            \"-force\",\n",
    "        ]\n",
    "    )\n",
    "    # calculate FOD data\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"dwi2fod\",\n",
    "            \"msmt_csd\",\n",
    "            Path(subject.root_path, subject.dmri_path),\n",
    "            Path(subject.root_path, \"wm_response.txt\"),\n",
    "            Path(subject.root_path, \"wmfod.nii\"),\n",
    "            Path(subject.root_path, \"gm_response.txt\"),\n",
    "            Path(subject.root_path, \"gm.nii\"),\n",
    "            Path(subject.root_path, \"csf_response.txt\"),\n",
    "            Path(subject.root_path, \"csf.nii\"),\n",
    "            \"-grad\",\n",
    "            subject.scheme_path,\n",
    "            \"-mask\",\n",
    "            Path(subject.root_path, subject.brain_mask_path),\n",
    "            \"-force\",\n",
    "        ]\n",
    "    )\n",
    "    # remove FOD data\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"mrconvert\",\n",
    "            Path(subject.root_path, \"wmfod.nii\"),\n",
    "            Path(subject.root_path, \"wm.nii\"),\n",
    "            \"-coord\",\n",
    "            \"3\",\n",
    "            \"0\",\n",
    "            \"-axes\",\n",
    "            \"0,1,2\",\n",
    "            \"-force\",\n",
    "        ]\n",
    "    )\n",
    "    # combine all scans\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"mrcat\",\n",
    "            Path(subject.root_path, \"gm.nii\"),\n",
    "            Path(subject.root_path, \"wm.nii\"),\n",
    "            Path(subject.root_path, \"csf.nii\"),\n",
    "            output_path,\n",
    "            \"-axis\",\n",
    "            \"3\",\n",
    "            \"-force\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    subject.fivett_mask_path = output_path\n",
    "    logger.info(\"finished 5tt generation, return code: %d\", result.returncode)\n",
    "    return result.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_and_mask_5tt(subject: MRISubjectData):\n",
    "    target_img = image.load_img(str(Path(subject.root_path, subject.brain_mask_path)))\n",
    "    target_affine = target_img.affine\n",
    "    target_shape = image.get_data(target_img).shape\n",
    "\n",
    "    source_img = image.load_img(str(subject.fivett_mask_path))\n",
    "    source_affine = source_img.affine\n",
    "    source_shape = image.get_data(source_img).shape\n",
    "\n",
    "    # correct 5tt mask affine if its not the same as the brain mask\n",
    "    # ------\n",
    "    if not np.allclose(target_affine, source_affine):\n",
    "        logger.warning(\"Affine values not the same, correcting...\")\n",
    "        source_img = image.resample_img(source_img, target_affine=target_affine, target_shape=target_shape)\n",
    "\n",
    "    # apply brain mask\n",
    "    # ------\n",
    "    img = np.transpose(apply_mask(source_img, target_img))\n",
    "\n",
    "    # binarize the 5tt mask\n",
    "    # ------\n",
    "    r = img.argmax(axis=1)  # roll index\n",
    "    _5tt_mask = np.c_[np.ones(img.shape[0]), np.zeros((img.shape[0], img.shape[1] - 1))]\n",
    "\n",
    "    # shift ones (1) from first column of _5tt_mask to the correct column with the roll index using this code:\n",
    "    # https://stackoverflow.com/a/20361561\n",
    "    rows, column_indices = np.ogrid[: _5tt_mask.shape[0], : _5tt_mask.shape[1]]\n",
    "    column_indices = column_indices - r[:, np.newaxis]\n",
    "    return _5tt_mask[rows, column_indices]\n",
    "\n",
    "\n",
    "def create_and_store_5tt(subjects):\n",
    "    for subject in subjects:\n",
    "        logger.info(\"Proccessing subject %s\", subject.subject_name)\n",
    "        if subject.fivett_mask_path is None and subject.t1_path is not None:\n",
    "            returncode = generate_5tt_mask(subject)\n",
    "            if returncode != 0:\n",
    "                logger.error(\"Could not generate 5tt masks\")\n",
    "                continue\n",
    "        elif subject.fivett_mask_path is None and subject.t1_path is None:\n",
    "            generate_tt_masks_by_dwi(subject)\n",
    "            \n",
    "\n",
    "        _5tt_bin_path = Path(subject.root_path, \"5tt_bin.npy\")\n",
    "        if not _5tt_bin_path.exists():\n",
    "            _5tt_data = binarize_and_mask_5tt(subject)\n",
    "            with open(_5tt_bin_path, \"wb\") as f:\n",
    "                np.save(f, _5tt_data.T)\n",
    "\n",
    "        with open(_5tt_bin_path, \"rb\") as f:\n",
    "            data = np.load(f)\n",
    "        \n",
    "        # Combine all masks into one:\n",
    "        if data.shape[0] == 5:\n",
    "            # - 0 = Grey Matter/gm\n",
    "            # - 1 = White Matter/wm\n",
    "            # - 2 = CSF\n",
    "            gm = data[0] + data[1]  # combine Cortical grey matter and Sub-cortical grey matter\n",
    "            wm = data[2]\n",
    "            csf = data[3]\n",
    "        else:\n",
    "            gm = data[0]\n",
    "            wm = data[1]\n",
    "            csf = data[2]\n",
    "            \n",
    "        wm[wm == 1] = 2\n",
    "        csf[csf == 1] = 3\n",
    "        masks = gm + wm + csf\n",
    "        masks -= 1\n",
    "                        \n",
    "        with h5py.File(subject.output_file, \"a\", libver=\"latest\") as archive:\n",
    "            key = \"masks\"\n",
    "            if key in archive.keys():\n",
    "                archive[key].resize((archive[key].shape[0] + masks.shape[0]), axis=0)\n",
    "                archive[key][-masks.shape[0] :] = masks\n",
    "            else:\n",
    "                dataset = archive.create_dataset(key, data=masks, dtype=\"i8\", chunks=(1024,), maxshape=(None,))\n",
    "                dataset.attrs[\"gm\"] = np.array([0])\n",
    "                dataset.attrs[\"wm\"] = np.array([1])\n",
    "                dataset.attrs[\"csf\"] = np.array([2])\n",
    "                dataset.attrs[\"wb\"] = np.array([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2022-02-07 14:24:10,849 - MUDI - INFO - Proccessing subject cdmri0011 (2063038349.py:34)\u001b[0m\n",
      "\u001b[38;21m2022-02-07 14:24:10,865 - MUDI - INFO - Proccessing subject cdmri0012 (2063038349.py:34)\u001b[0m\n",
      "\u001b[38;21m2022-02-07 14:24:10,876 - MUDI - INFO - Proccessing subject cdmri0013 (2063038349.py:34)\u001b[0m\n",
      "\u001b[38;21m2022-02-07 14:24:10,887 - MUDI - INFO - Proccessing subject cdmri0014 (2063038349.py:34)\u001b[0m\n",
      "\u001b[38;21m2022-02-07 14:24:10,901 - MUDI - INFO - Proccessing subject cdmri0015 (2063038349.py:34)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "create_and_store_5tt(mri_mudi_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = np.concatenate((subj11, subj12, subj13, subj14, subj15), axis=0)\n",
    "print(subj.shape)\n",
    "masked_data = np.concatenate(\n",
    "    (masked_data11n, masked_data12n, masked_data13n, masked_data14n, masked_data15n),\n",
    "    axis=0,\n",
    ")\n",
    "print(masked_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate((subj[:, np.newaxis], masked_data), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc16 = \"./data\"\n",
    "masked_data16 = np.transpose(\n",
    "    apply_mask(\n",
    "        imgs=os.path.join(direc16, \"16_MB_RE_t.nii.gz\"),\n",
    "        mask_img=os.path.join(direc16, \"brain_mask-testing1.nii.gz\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc17 = \"./data\"\n",
    "masked_data17 = np.transpose(\n",
    "    apply_mask(\n",
    "        imgs=os.path.join(direc17, \"17_MB_RE_t.nii.gz\"),\n",
    "        mask_img=os.path.join(direc17, \"brain_mask-testing2.nii.gz\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med16 = np.median(masked_data16[:, mask2], axis=0)\n",
    "med17 = np.median(masked_data17[:, mask2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med11_ = np.median(masked_data11[:, mask3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a16, _, _, _ = np.linalg.lstsq(med16[:, np.newaxis], med11_)\n",
    "a17, _, _, _ = np.linalg.lstsq(med17[:, np.newaxis], med11_)\n",
    "print(a16, a17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(20, 5))\n",
    "axes[0].plot(med16, med11_, \"yo\", med16, med16 * a16, \":k\", med16, med16, \"-k\")\n",
    "axes[1].plot(med17, med11_, \"bo\", med17, med17 * a17, \":k\", med17, med17, \"-k\")\n",
    "for ax in axes:\n",
    "    ax.set(aspect=\"equal\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = image.index_img(os.path.join(direc11, img_file), np.array(selecind[[1, 10, 100, 300]]))\n",
    "for img in image.iter_img(selected_imgs):\n",
    "    # img is now an in-memory 3D img\n",
    "    plotting.plot_anat(img, vmin=0, vmax=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = image.index_img(os.path.join(direc16, \"16_MB_RE_t.nii.gz\"), np.array([1, 10, 100, 300]))\n",
    "for img in image.iter_img(selected_imgs):\n",
    "    # img is now an in-memory 3D img\n",
    "    plotting.plot_anat(img, vmin=0, vmax=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data16n = masked_data16.astype(\"float32\") * a16 / max_data\n",
    "masked_data17n = masked_data17.astype(\"float32\") * a17 / max_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj16 = 16 * np.ones((masked_data16.shape[0],), dtype=int)\n",
    "subj17 = 17 * np.ones((masked_data17.shape[0],), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = np.concatenate((subj16, subj17), axis=0)\n",
    "print(subj.shape)\n",
    "masked_data = np.concatenate((masked_data16n, masked_data17n), axis=0)\n",
    "print(masked_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(subj16) + len(subj17))\n",
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.concatenate((ind[:, np.newaxis], subj[:, np.newaxis]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"header_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File(\"data_test.hdf5\", \"w\")\n",
    "h5f.create_dataset(\"data1\", data=masked_data)\n",
    "h5f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_data = masked_data11.max()\n",
    "max_data = np.percentile(masked_data11, 95)\n",
    "masked_data11n = masked_data11.astype(\"float32\") / max_data\n",
    "masked_data12n = masked_data12.astype(\"float32\") * a12 / max_data\n",
    "masked_data13n = masked_data13.astype(\"float32\") * a13 / max_data\n",
    "masked_data14n = masked_data14.astype(\"float32\") * a14 / max_data\n",
    "masked_data15n = masked_data15.astype(\"float32\") * a15 / max_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_data)\n",
    "print(masked_data11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, sharey=True, figsize=(20, 10))\n",
    "axes[0].hist(masked_data11n.flatten(), range=[0, 1])\n",
    "axes[1].hist(masked_data12n.flatten(), range=[0, 1])\n",
    "axes[2].hist(masked_data13n.flatten(), range=[0, 1])\n",
    "axes[3].hist(masked_data14n.flatten(), range=[0, 1])\n",
    "axes[4].hist(masked_data15n.flatten(), range=[0, 1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj11 = 11 * np.ones((masked_data11.shape[0],), dtype=int)\n",
    "subj12 = 12 * np.ones((masked_data12.shape[0],), dtype=int)\n",
    "subj13 = 13 * np.ones((masked_data13.shape[0],), dtype=int)\n",
    "subj14 = 14 * np.ones((masked_data14.shape[0],), dtype=int)\n",
    "subj15 = 15 * np.ones((masked_data15.shape[0],), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = np.concatenate((subj11, subj12, subj13, subj14, subj15), axis=0)\n",
    "print(subj.shape)\n",
    "masked_data = np.concatenate(\n",
    "    (masked_data11n, masked_data12n, masked_data13n, masked_data14n, masked_data15n),\n",
    "    axis=0,\n",
    ")\n",
    "print(masked_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(subj11) + len(subj12) + len(subj13) + len(subj14) + len(subj15))\n",
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.concatenate((ind[:, np.newaxis], subj[:, np.newaxis]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"header_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6623f10d21f7cd42380353d1b2afd90f10262effa2dc8ec2464c62b1bda5533"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
