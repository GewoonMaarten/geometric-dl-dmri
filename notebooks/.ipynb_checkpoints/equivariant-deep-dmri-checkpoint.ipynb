{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivariant deep dmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from equideepdmri.utils.q_space import Q_SamplingSchema\n",
    "from equideepdmri.network.VoxelWiseSegmentationNetwork import VoxelWiseSegmentationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: 1\n",
      "active device: _CudaDeviceProperties(name='GeForce GTX 1080', major=6, minor=1, total_memory=8118MB, multi_processor_count=20)\n"
     ]
    }
   ],
   "source": [
    "print(f'gpus: {torch.cuda.device_count()}')\n",
    "print(f'active device: {torch.cuda.get_device_properties(torch.cuda.current_device())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorFormatter(logging.Formatter):\n",
    "    \"\"\"Logging Formatter to add colors and count warning / errors\"\"\"\n",
    "\n",
    "    grey = \"\\x1b[38;21m\"\n",
    "    yellow = \"\\x1b[33;21m\"\n",
    "    red = \"\\x1b[31;21m\"\n",
    "    bold_red = \"\\x1b[31;1m\"\n",
    "    reset = \"\\x1b[0m\"\n",
    "    format = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s (%(filename)s:%(lineno)d)\"\n",
    "\n",
    "    FORMATS = {\n",
    "        logging.DEBUG: grey + format + reset,\n",
    "        logging.INFO: grey + format + reset,\n",
    "        logging.WARNING: yellow + format + reset,\n",
    "        logging.ERROR: red + format + reset,\n",
    "        logging.CRITICAL: bold_red + format + reset\n",
    "    }\n",
    "\n",
    "    def format(self, record):\n",
    "        log_fmt = self.FORMATS.get(record.levelno)\n",
    "        formatter = logging.Formatter(log_fmt)\n",
    "        return formatter.format(record)\n",
    "\n",
    "def init_logger(name, log_level):\n",
    "    \"\"\"Create a logger and add a colored formatter if not added already\"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(log_level)\n",
    "    if not logger.hasHandlers():\n",
    "        stream = logging.StreamHandler()\n",
    "        stream.setLevel(logging.DEBUG)\n",
    "        stream.setFormatter(ColorFormatter())\n",
    "        \n",
    "        logger.addHandler(stream)\n",
    "\n",
    "logger_name = 'mudi'\n",
    "init_logger(logger_name, logging.DEBUG) # <- set this to something like logging.ERROR when training for real\n",
    "logger = logging.getLogger(logger_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from Rotation-Equivariant Deep Learning for Diffusion MRI\n",
    "See: [github.com/philip-mueller/equivariant-deep-dmri](https://github.com/philip-mueller/equivariant-deep-dmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_label_weights(training_dataloader: DataLoader) -> torch.Tensor:\n",
    "    num_P_voxels = 0.\n",
    "    num_total_voxels = 0.\n",
    "    for i, batch in enumerate(training_dataloader):\n",
    "        target: torch.Tensor = batch['target']\n",
    "        brain_mask = batch['brain_mask'].bool()\n",
    "        target = target[brain_mask]\n",
    "        num_P_voxels += float(target.nonzero().size(0))\n",
    "        num_total_voxels += float(target.numel())\n",
    "\n",
    "    return torch.tensor(1 - (num_P_voxels/num_total_voxels))\n",
    "\n",
    "\n",
    "class RandomDMriSegmentationDataset:\n",
    "    def __init__(self, N, Q, num_b0, p_size: tuple):\n",
    "        self.N = N\n",
    "        assert Q >= num_b0\n",
    "\n",
    "        q_vectors = torch.rand(Q, 3)\n",
    "        q_vectors[:num_b0, :] = 0.0\n",
    "        self.q_sampling_schema = Q_SamplingSchema(q_vectors)\n",
    "\n",
    "        assert len(p_size) == 3\n",
    "        self.scans = torch.randn(N, Q, *p_size)\n",
    "        self.targets = (torch.randn(N, *p_size) > 0.8).float()\n",
    "        self.brain_masks = torch.ones(N, *p_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert isinstance(i, int)  # only batch-size == 1\n",
    "\n",
    "        return {'sample_id': str(i), 'input': self.scans[i],\n",
    "                'target': self.targets[i], 'brain_mask': self.brain_masks[i] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoxelWiseSegmentationNetwork(\n",
      "  (pq_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (conv): <EquivariantPQLayer (1,)->(11, 4)>\n",
      "      (non_linearity): GatedBlockNonLin()\n",
      "    )\n",
      "  )\n",
      "  (q_reduction_layer): QLengthWeightedAvgPool(\n",
      "    (radial_basis): FiniteElement_RadialBasis(\n",
      "      (model): FC()\n",
      "    )\n",
      "  )\n",
      "  (p_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (conv): <EquivariantPLayer (7, 4)->(25, 5)>\n",
      "      (non_linearity): GatedBlockNonLin()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (conv): <EquivariantPLayer (20, 5)->(13, 3)>\n",
      "      (non_linearity): GatedBlockNonLin()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (conv): <EquivariantPLayer (10, 3)->(7, 2)>\n",
      "      (non_linearity): GatedBlockNonLin()\n",
      "    )\n",
      "    (3): <EquivariantPLayer (5, 2)->(1,)>\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset = RandomDMriSegmentationDataset(N=10, Q=8, num_b0=2, p_size=(10, 10, 10))\n",
    "model = VoxelWiseSegmentationNetwork(\n",
    "    q_sampling_schema_in=dataset.q_sampling_schema,\n",
    "    pq_channels=[\n",
    "        [7, 4]\n",
    "    ],\n",
    "    p_channels=[\n",
    "        [20, 5],\n",
    "        [10, 3],\n",
    "        [5, 2],\n",
    "        [1]\n",
    "    ],\n",
    "    pq_kernel={\n",
    "        'kernel':'pq_TP',\n",
    "        'p_radial_basis_type':'cosine'\n",
    "    },\n",
    "    p_kernel={\n",
    "        'p_radial_basis_type':'cosine'\n",
    "    },\n",
    "    kernel_sizes=5,\n",
    "    non_linearity={\n",
    "        'tensor_non_lin':'gated',\n",
    "        'scalar_non_lin':'swish'\n",
    "    },\n",
    "    q_reduction={\n",
    "        'reduction':'length_weighted_average'\n",
    "    }\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-10 10:40:03,503 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,611 - mudi - INFO - loss 2.8891196250915527 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,688 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,762 - mudi - INFO - loss 2.5472934246063232 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,798 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,867 - mudi - INFO - loss 2.2615816593170166 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,898 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:03,968 - mudi - INFO - loss 1.9356001615524292 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,003 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,075 - mudi - INFO - loss 1.6618397235870361 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,110 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,180 - mudi - INFO - loss 1.3968778848648071 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,211 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,279 - mudi - INFO - loss 1.2323205471038818 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,311 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,382 - mudi - INFO - loss 1.1207078695297241 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,419 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,487 - mudi - INFO - loss 1.028164029121399 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,520 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,588 - mudi - INFO - loss 0.9603902101516724 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,622 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,696 - mudi - INFO - loss 0.9323583841323853 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,729 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,796 - mudi - INFO - loss 0.9106195569038391 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,832 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,901 - mudi - INFO - loss 0.8613954782485962 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:04,933 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,002 - mudi - INFO - loss 0.8531686663627625 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,035 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,106 - mudi - INFO - loss 0.8289666175842285 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,137 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,208 - mudi - INFO - loss 0.8229532241821289 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,239 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,306 - mudi - INFO - loss 0.797568142414093 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,336 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,406 - mudi - INFO - loss 0.8064382076263428 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,437 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,511 - mudi - INFO - loss 0.7937561273574829 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,542 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,615 - mudi - INFO - loss 0.8051166534423828 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,649 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,716 - mudi - INFO - loss 0.7766392827033997 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,746 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,812 - mudi - INFO - loss 0.7768457531929016 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,842 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,910 - mudi - INFO - loss 0.7633723020553589 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:05,939 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,005 - mudi - INFO - loss 0.7433769702911377 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,037 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,108 - mudi - INFO - loss 0.7370971441268921 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,139 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,206 - mudi - INFO - loss 0.741329550743103 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,242 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,312 - mudi - INFO - loss 0.7269311547279358 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,345 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,415 - mudi - INFO - loss 0.7252691984176636 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,445 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,520 - mudi - INFO - loss 0.7315768003463745 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,554 - mudi - DEBUG - torch.Size([1, 8, 10, 10, 10]) (<ipython-input-9-2499bc7ed611>:18)\u001b[0m\n",
      "\u001b[38;21m2021-06-10 10:40:06,622 - mudi - INFO - loss 0.7146897912025452 (<ipython-input-9-2499bc7ed611>:26)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=True)\n",
    "pos_weight = compute_binary_label_weights(dataloader)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5.0e-03)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in iter(dataloader):\n",
    "        sample_ids, x, target, brain_mask = batch['sample_id'], batch['input'], batch['target'], batch['brain_mask']\n",
    "        \n",
    "\n",
    "        assert brain_mask.size(0) == 1 and len(sample_ids) == 1 and target.size(0) == 1 and x.size(0) == 1, \\\n",
    "                        'Currently only batch-size 1 is supported'\n",
    "        sample_ids = sample_ids[0]\n",
    "        brain_mask = brain_mask.squeeze(0).bool()  # (Z x Y x X)\n",
    "        target = target.squeeze(0)[brain_mask]  # (num_non_masked_voxels)\n",
    "        # note: x is not squeezed as model expected batch dim, it is squeezed after model is applied\n",
    "        \n",
    "        logger.debug(f'{x.shape}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predicted_scores = model(x).squeeze(0)  # (Z x Y x X)\n",
    "        predicted_scores = predicted_scores[brain_mask]  # (num_non_masked_voxels)\n",
    "        loss = criterion(predicted_scores, target)\n",
    "        \n",
    "        logger.info(f'loss {float(loss)}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRISelectorSubjDataset(Dataset):\n",
    "    \"\"\"MRI dataset to select features from\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, dataf, headerf, subj_list):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Args:\n",
    "            root_dir (string): Directory with the .csv files\n",
    "            data (string): Data .csv file\n",
    "            header (string): Header .csv file\n",
    "            subj_list (list): list of all the subjects to include\n",
    "            \n",
    "            batch_size & shuffle are defined with 'DataLoader' in pytorch \n",
    "        \"\"\"     \n",
    "        self.root_dir = root_dir\n",
    "        self.dataf = dataf\n",
    "        \n",
    "        # load the header\n",
    "        header = pd.read_csv(os.path.join(self.root_dir, headerf), index_col=0).to_numpy()\n",
    "        self.ind = header[np.isin(header[:,1], subj_list), 0]\n",
    "        \n",
    "        self.indexes = np.arange(len(self.ind))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.ind)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        logger.debug(f'loading data for index: {index}')\n",
    "        indexes = self.indexes[index]\n",
    "\n",
    "        # Find list of IDs\n",
    "        #list_IDs_temp = [self.ind[k] for k in indexes]\n",
    "        list_IDs_temp = self.ind[indexes]\n",
    "        \n",
    "        h5f = h5py.File(os.path.join(self.root_dir, self.dataf), 'r')\n",
    "        X = h5f.get('data1')\n",
    "        X = X[list_IDs_temp,:]\n",
    "        \n",
    "        logger.debug(f'Data for index {index}: {X}{X.shape}')\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-08 15:13:45,221 - mudi - DEBUG - loading data for index: 1 (<ipython-input-24-9f2c8dedc506>:31)\u001b[0m\n",
      "\u001b[38;21m2021-06-08 15:13:45,223 - mudi - DEBUG - Data for index 1: [0.01232295 0.00841025 0.01193968 ... 0.01052783 0.00930519 0.01574411](1344,) (<ipython-input-24-9f2c8dedc506>:42)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01232295, 0.00841025, 0.01193968, ..., 0.01052783, 0.00930519,\n",
       "       0.01574411], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = './data'\n",
    "dataf = 'data_.hdf5'\n",
    "headerf = 'header_.csv'\n",
    "subj_list_train = np.array([11, 12, 13, 14])\n",
    "subj_list_valid = np.array([15])\n",
    "\n",
    "train_set = MRISelectorSubjDataset(root_dir, dataf, headerf, subj_list_train)\n",
    "train_set.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.masking import apply_mask\n",
    "import os\n",
    "\n",
    "img_file = 'MB_Re_t_moco_registered_applytopup.nii.gz'\n",
    "msk_file = 'brain_mask.nii.gz'\n",
    "\n",
    "direc11 = './data/cdmri0011/'\n",
    "\n",
    "masked_data11 = np.transpose(apply_mask(imgs=os.path.join(direc11, img_file),\n",
    "                                        mask_img=os.path.join(direc11, msk_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 108300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(masked_data11).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
