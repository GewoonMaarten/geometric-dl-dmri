{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Autoencoders dMRI for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_path # Always import this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.env import DATA_PATH\n",
    "from utils.logger import logger, logging_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path().cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info('torch version %s', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available, else cpu\n",
    "has_cuda = torch.cuda.is_available()\n",
    "\n",
    "logger.info(\"Is the GPU available? %s\", has_cuda)\n",
    "logger.info(\"Current device: %s\", torch.cuda.current_device())\n",
    "logger.info(\"Device count: %s\", torch.cuda.device_count())\n",
    "\n",
    "device = torch.device(\"cuda\" if has_cuda else \"cpu\")\n",
    "if has_cuda:\n",
    "    logger.info(\"Using device: %s\", torch.cuda.get_device_properties(device))\n",
    "else:\n",
    "    logger.warning(\"No GPU dectected! Training will be extremly slow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils.concrete import (\n",
    "    ConcreteAutoencoderFeatureSelector,\n",
    "    decoder_1l,\n",
    "    decoder_2l,\n",
    "    decoder_3l,\n",
    ")\n",
    "from utils.dataset import MRISelectorSubjDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_subject, test_subject, params):\n",
    "    \"\"\"\n",
    "    Trains the ConcreteAutoencoderFeatureSelector\n",
    "\n",
    "    Parameters:\n",
    "        train_subject (List): subjects to train on\n",
    "        test_subject (List): subjects to test on\n",
    "        params (Dict): model parameters to grid search on.\n",
    "    \"\"\"\n",
    "    strftime = \"%Y%m%d%H%M%S\"\n",
    "    writer = SummaryWriter(\n",
    "        log_dir=Path(ROOT_PATH, \"runs\", datetime.now().strftime(strftime))\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(14)\n",
    "\n",
    "    for run in RunBuilder.get_runs(params):\n",
    "        logger.info(\"running: %s\", run)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        model_info_template_str = f\"{now:%Y%m%d%H%M%S}_lr={run.lr}_batch_size={run.batch_size}_num_epochs={run.num_epochs}_n_features={run.n_features}_decoder={run.decoder.__name__}_test={test_subject[0]}\"\n",
    "\n",
    "        checkpoint_path = str(\n",
    "            Path(ROOT_PATH, \"runs\", \"models\", f\"{model_info_template_str}_runtime.h5\")\n",
    "        )\n",
    "        monitor_callback = ModelCheckpoint(\n",
    "            checkpoint_path, monitor=\"val_loss\", verbose=True\n",
    "        )\n",
    "\n",
    "        root_dir = Path(ROOT_PATH, \"data\")\n",
    "        dataf = \"data_.hdf5\"\n",
    "        headerf = \"header_.csv\"\n",
    "        subj_list_train = np.array(train_subject)\n",
    "        subj_list_valid = np.array(test_subject)\n",
    "\n",
    "        train_set = MRISelectorSubjDataset(root_dir, dataf, headerf, subj_list_train)\n",
    "        train_gen = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=run.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        # for the validation dataset\n",
    "        valid_set = MRISelectorSubjDataset(root_dir, dataf, headerf, subj_list_valid)\n",
    "        valid_gen = DataLoader(\n",
    "            valid_set,\n",
    "            batch_size=run.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        # 1st time\n",
    "        checkpt = False\n",
    "        # Continue training\n",
    "        # checkpt = True\n",
    "        # temp = Tensor([10]) # check last value if necessary\n",
    "\n",
    "        selector = ConcreteAutoencoderFeatureSelector(\n",
    "            K=run.n_features,\n",
    "            decoder=run.decoder,\n",
    "            device=device,\n",
    "            num_features=run.n_features,\n",
    "            num_epochs=run.num_epochs,\n",
    "            learning_rate=run.lr,\n",
    "            start_temp=10,\n",
    "            min_temp=0.1,\n",
    "            tryout_limit=1,\n",
    "            input_dim=1344,\n",
    "            checkpt=checkpt,\n",
    "            callback=monitor_callback,\n",
    "            writer=writer,\n",
    "            path=ROOT_PATH,\n",
    "        )  # ,losstrain=losstrain,lossval=lossval)\n",
    "\n",
    "        selector.fit(X=train_gen, val_X=valid_gen)\n",
    "\n",
    "        model = selector.get_params()\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            Path(ROOT_PATH, \"runs\", \"models\", f\"{model_info_template_str}_params.pt\"),\n",
    "        )\n",
    "\n",
    "        indices = selector.get_indices().to(\"cpu\")\n",
    "        logger.info(np.sort(indices))\n",
    "        np.savetxt(\n",
    "            Path(ROOT_PATH, \"runs\", \"models\", f\"{model_info_template_str}.txt\"),\n",
    "            np.array(indices, dtype=int),\n",
    "            fmt=\"%d\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "We use a learning rate of 0.001, batch size of 265 and 2000 epochs. 2000 Epochs is likely not enough to get a high mean max of probabilities, but otherwise training takes too long. Our input size is 1344, so for the latent space we take half that, and continue halving for five more latent space sizes. Lastly we have 3 decoders of various complexities. `decoder_1l` being the least complex and `decoder_3l` the most complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    [11, 12, 13, 14],\n",
    "    [15],\n",
    "    OrderedDict(\n",
    "        lr=[0.001],\n",
    "        batch_size=[256],\n",
    "        num_epochs=[2000],\n",
    "        n_features=[21, 42, 84, 168, 336, 672],  # latent space sizes\n",
    "        decoder=[decoder_1l, decoder_2l, decoder_3l],\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0d8aa0de02be0b131f97d6c1ce0bb8282df47d74804acd542e4e3d0f3fd66dc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
