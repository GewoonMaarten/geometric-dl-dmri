{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Autoencoders dMRI for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_path # Always import this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch import reshape as tshape\n",
    "from torch import matmul as tmat\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.env import DATA_PATH\n",
    "from utils.logger import logger, logging_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path().cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-11 19:45:08,195 - geometric-dl - INFO - torch version 1.8.1 (<ipython-input-4-a395a760577f>:1)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info('torch version %s', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-11 19:45:08,243 - geometric-dl - INFO - Current device: 0 (<ipython-input-5-bfdeb86c5565>:1)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 19:45:08,244 - geometric-dl - INFO - Device count: 1 (<ipython-input-5-bfdeb86c5565>:2)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 19:45:08,245 - geometric-dl - INFO - Is the GPU available? True (<ipython-input-5-bfdeb86c5565>:3)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 19:45:08,247 - geometric-dl - INFO - Using device: _CudaDeviceProperties(name='NVIDIA GeForce GTX 1080', major=6, minor=1, total_memory=8118MB, multi_processor_count=20) (<ipython-input-5-bfdeb86c5565>:7)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info('Current device: %s', torch.cuda.current_device())\n",
    "logger.info('Device count: %s', torch.cuda.device_count())\n",
    "logger.info('Is the GPU available? %s', torch.cuda.is_available())\n",
    "\n",
    "# # use gpu if available, else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info('Using device: %s', torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUDI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# packages related to data reading\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# pytorch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRISelectorSubjDataset(Dataset):\n",
    "    \"\"\"MRI dataset to select features from.\"\"\"\n",
    "    \n",
    "    # pytorch\n",
    "    def __init__(self, root_dir, dataf, headerf, subj_list):\n",
    "        \"\"\"\n",
    "        batch_size & shuffle are defined with 'DataLoader' in pytorch \n",
    "\n",
    "        Args:\n",
    "            root_dir (string): Directory with the .csv files\n",
    "            data (string): Data .csv file\n",
    "            header (string): Header .csv file\n",
    "            subj_list (list): list of all the subjects to include\n",
    "        \"\"\"\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.dataf = dataf\n",
    "        self.headerf = headerf\n",
    "        self.subj_list = subj_list\n",
    "        \n",
    "        # load the header\n",
    "        subj = self.subj_list[0]\n",
    "        self.header = pd.read_csv(os.path.join(self.root_dir, self.headerf), index_col=0).to_numpy()\n",
    "        self.ind = self.header[np.isin(self.header[:,1],self.subj_list),0]\n",
    "        \n",
    "        self.indexes = np.arange(len(self.ind))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.ind)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        indexes = self.indexes[index]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        #list_IDs_temp = [self.ind[k] for k in indexes]\n",
    "        list_IDs_temp = self.ind[indexes]\n",
    "        \n",
    "        h5f = h5py.File(os.path.join(self.root_dir, self.dataf), 'r')\n",
    "        X = h5f.get('data1')\n",
    "        X = X[list_IDs_temp,:]\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle as pk\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.base import Callback\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcreteSelect(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim, input_shape, n_features = 500, start_temp = 10.0, min_temp = 0.1, alpha = 0.99999, **kwargs):\n",
    "        super(ConcreteSelect, self).__init__(**kwargs)\n",
    "        # encoder\n",
    "        self.output_dim = output_dim\n",
    "        self.input_shape = input_shape # the input layer has output (None,N_params_in). In this case, probably equal to input_dim\n",
    "        self.start_temp = start_temp\n",
    "        #self.min_temp = K.constant(min_temp)\n",
    "        self.min_temp = nn.init.constant_(Tensor(np.zeros(1)),min_temp).to(device)\n",
    "        #self.alpha = K.constant(alpha)\n",
    "        self.alpha = nn.init.constant_(Tensor(np.zeros(1)),alpha).to(device)\n",
    "        #self.name = name\n",
    "              \n",
    "        # equivalent to build in Keras\n",
    "        self.temp = Variable(Tensor([self.start_temp]), requires_grad = False).to(device)\n",
    "        tensor_logits = nn.init.xavier_normal_(torch.empty(self.output_dim,self.input_shape)).to(device)\n",
    "        self.logits = nn.Parameter(tensor_logits, requires_grad = True).to(device)\n",
    "\n",
    "        # for the decoder, we define three different Linear/dense layers and the activation function\n",
    "        self.dense800 = nn.Linear(n_features,800)\n",
    "        #self.dense800 = nn.Linear(500,800) # the example for the standard 500 features value\n",
    "        self.dense1000 = nn.Linear(800,1000)\n",
    "        self.dense1344 = nn.Linear(1000,1344)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    # equivalent to call in Keras -> encoder, the concrete layer itself   \n",
    "    def encoder(self, X, training = None):\n",
    "        \n",
    "        uniform = torch.rand(self.logits.size()).to(device)\n",
    "        gumbel = -torch.log(-torch.log(uniform)).to(device)\n",
    "        self.temp = torch.maximum(self.min_temp, self.temp * self.alpha).to(device)\n",
    "        #print('temperature {}'.format(self.temp))\n",
    "        #noisy_logits = (self.logits + gumbel.to(device)) / self.temp\n",
    "        noisy_logits = ((self.logits + gumbel) / self.temp).to(device)\n",
    "        samples = F.softmax(noisy_logits, dim = 1)\n",
    "                \n",
    "        #numClasses = self.logits.size()[1]\n",
    "        dim_argmax = len(self.logits.size())-1\n",
    "        discrete_logits = F.one_hot(torch.argmax(self.logits.to(device),dim_argmax),num_classes = self.logits.size()[1])\n",
    "        \n",
    "        # probably unnecessary\n",
    "        if training is None:\n",
    "            training = self.training\n",
    "        \n",
    "        if self.training:\n",
    "            self.selections = samples\n",
    "        else:\n",
    "            self.selections = discrete_logits\n",
    "        \n",
    "        #Y = torch.dot(X,torch.transpose(self.selections, 0, 1)) \n",
    "        # dot is not exactly equal to a dot product, it could be a matrix product in keras \n",
    "        Y = torch.matmul(X,torch.transpose(self.selections.float(), 0, 1))\n",
    "        return Y\n",
    "    \n",
    "    # decoder: we suppose the two-layers scheme. In keras this is defined outside\n",
    "    def decoder(self,x):\n",
    "        #x.to(\"cpu\")\n",
    "        x = self.act(self.dense800(x))\n",
    "        x = self.act(self.dense1000(x))\n",
    "        x = self.dense1344(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, X, training = None):\n",
    "        y = self.encoder(X) # selected features\n",
    "        x = self.decoder(y) # reconstructed signals\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopperCallback(EarlyStopping):\n",
    "    \n",
    "    def __init__(self, mean_max_target = 0.998):#, writer=None):\n",
    "        self.mean_max_target = mean_max_target\n",
    "        #self.writer = writer\n",
    "        #super(StopperCallback, self).__init__(monitor = '', patience = float('inf'), verbose = 1, mode = 'max')#, baseline = self.mean_max_target)\n",
    "        super(StopperCallback, self).__init__(monitor = '', patience = float('inf'), verbose = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConcreteAutoencoderFeatureSelector():\n",
    "    \n",
    "    #def __init__(self, K, output_function, num_epochs = 100, learning_rate = 0.001, start_temp = 10.0, min_temp = 0.1, tryout_limit = 5, input_dim = 1344, callback=None, writer=None): #batch_size = None, \n",
    "    def __init__(self, K, num_features = 500, num_epochs = 100, learning_rate = 0.001, start_temp = 10.0, min_temp = 0.1, tryout_limit = 5, input_dim = 1344, checkpt=True, callback=None, writer=None, path = ''):#, losstrain=None, lossval=None): #batch_size = None, \n",
    "        self.K = K # equivalent to output_dim\n",
    "        # self.output_function = output_function # this function is now included in the ConcreteSelect class\n",
    "        # but now we have to define the number of features to be extracted from the encoder\n",
    "        self.num_features = num_features\n",
    "        self.num_epochs = num_epochs\n",
    "#         self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.start_temp = start_temp\n",
    "        self.min_temp = min_temp\n",
    "        self.tryout_limit = tryout_limit\n",
    "        self.input_dim = input_dim\n",
    "        self.checkpt = checkpt\n",
    "        self.callback = callback\n",
    "        self.writer = writer\n",
    "        self.path = path #str(Path(ROOT_PATH, 'runs', 'models'))\n",
    "        #self.losstrain = losstrain\n",
    "        #self.lossval = lossval\n",
    "        \n",
    "    def fit(self, X, val_X=None):\n",
    "#         if self.batch_size is None:\n",
    "#             self.batch_size = max(len(X) // 256, 16)\n",
    "        \n",
    "        num_epochs = self.num_epochs\n",
    "        steps_per_epoch = X.__len__()#(len(X) + self.batch_size - 1) // self.batch_size\n",
    "        logger.info(\"steps per epoch: %s\", steps_per_epoch)\n",
    "        writer = self.writer\n",
    "        #losses,losses_val=[],[]\n",
    "        \n",
    "        for i in range(self.tryout_limit):\n",
    "            \n",
    "            alpha = math.exp(math.log(self.min_temp / self.start_temp) / (num_epochs * steps_per_epoch))\n",
    "            \n",
    "            # we apply the model\n",
    "            self.model = ConcreteSelect(self.K, self.input_dim, self.num_features, self.start_temp, self.min_temp, alpha).cuda()\n",
    "            \n",
    "            # we define the loss and the optimizer functions\n",
    "            criterion = nn.MSELoss().cuda()\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(),lr=self.learning_rate) \n",
    "            \n",
    "            if self.checkpt==True:\n",
    "                checkpoint = torch.load(self.path)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                epoch_check = checkpoint['epoch']\n",
    "                loss = checkpoint['loss']\n",
    "            self.model.train()\n",
    "            \n",
    "            stopper_callback = StopperCallback()#writer=self.writer)\n",
    "\n",
    "            logger.info('%s', self.callback)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                if self.checkpt==True:\n",
    "                    if epoch < epoch_check:\n",
    "                        continue\n",
    "                \n",
    "                value_stop = torch.mean(torch.max(F.softmax(self.model.logits, dim = 1),1).values)\n",
    "                logger.info('mean max of probabilities: %s %s %s', value_stop, '- temperature', self.model.temp)\n",
    "                \n",
    "                if value_stop >= stopper_callback.mean_max_target:\n",
    "                    break\n",
    "                \n",
    "                self.model.train()\n",
    "                with torch.profiler.profile(\n",
    "                    activities=[\n",
    "                        torch.profiler.ProfilerActivity.CPU,\n",
    "                        torch.profiler.ProfilerActivity.CUDA],\n",
    "                    schedule=torch.profiler.schedule(\n",
    "                        wait=2,\n",
    "                        warmup=3,\n",
    "                        active=6),\n",
    "                    on_trace_ready=torch.profiler.tensorboard_trace_handler('./logs', worker_name='worker0'),\n",
    "                    record_shapes=True,\n",
    "                    profile_memory=True,\n",
    "                    with_stack=True\n",
    "                ) as p:\n",
    "                    for j, signals in enumerate(X):\n",
    "                        signals = signals.to(device)\n",
    "                        # just to check how it's going, the next two lines can be commented or removed\n",
    "                        if(j%500 == 0):\n",
    "                            logger.info(\"iteration: %s\", j)\n",
    "\n",
    "                        # steps in pytorch:\n",
    "                        # 1. Initialise gradients at the start of each batch\n",
    "                        # 2. Run the forward and then the backwards pass\n",
    "                        # 3. Compute the loss and update the weights\n",
    "\n",
    "                        # Initialise gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        outputs, selected_features = self.model(signals)\n",
    "                        loss = criterion(outputs, signals) # like criterion(yhat,target) -> the target in the autoencoder is the input\n",
    "\n",
    "                        writer.add_scalar(str(Path(ROOT_PATH, 'runs', 'scalars')), loss, epoch)\n",
    "\n",
    "                        #print('Epoch {}: Loss = {}'.format(epoch+1, loss.item())) # just to check how it's going\n",
    "\n",
    "                        # Backward pass\n",
    "                        loss.backward()\n",
    "\n",
    "                        # Compute the loss and update the weights\n",
    "                        optimizer.step()\n",
    "                        p.step()\n",
    "                        \n",
    "                if val_X is not None:\n",
    "                    # Evaluate the model\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                    #steps_per_epoch_val = val_X.__len__()\n",
    "                    for j, signals in enumerate(val_X):\n",
    "                        signals = signals.to(device)\n",
    "                        outputs_pred, selected_features_pred = self.model(signals)\n",
    "\n",
    "                        loss = criterion(outputs_pred,signals)\n",
    "                \n",
    "                # save for checkpoint\n",
    "                torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item(),\n",
    "                        }, self.path)\n",
    "                \n",
    "            num_epochs *= 2\n",
    "        \n",
    "        self.probabilities = F.softmax(self.model.logits, dim = 1)\n",
    "        self.indices = torch.argmax(self.model.logits, 1)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_indices(self):\n",
    "        val = torch.argmax(self.model.logits, 1)\n",
    "        return val\n",
    "        #return K.get_value(K.argmax(self.model.get_layer('concrete_select').logits))\n",
    "    \n",
    "    def get_mask(self):\n",
    "        #nn.functional.one_hot(torch.argmax(self.logits),list(self.logits.size())[1], dim = )\n",
    "        dim_argmax = len(self.model.logits.size())-1\n",
    "        val = torch.sum(nn.functional.one_hot(torch.argmax(self.model.logits,dim_argmax),self.model.logits.size()[1]))\n",
    "        return val\n",
    "        #return K.get_value(K.sum(K.one_hot(K.argmax(self.model.get_layer('concrete_select').logits), self.model.get_layer('concrete_select').logits.shape[1]), axis = 0))\n",
    "    \n",
    "\n",
    "    def get_support(self, indices = False):\n",
    "        return self.get_indices() if indices else self.get_mask()\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.model\n",
    "        #return self.output_function(self.concrete_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    lr = [.001],\n",
    "    batch_size = [256]\n",
    "#     batch_size = [64]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_means = 50\n",
    "num_epochs = 1\n",
    "#dec = decoder_2l\n",
    "#dec = mudi_net(n_meas)\n",
    "decstr = 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 15\n",
    "testsubjstr = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-11 15:14:27,555 - geometric-dl - INFO - steps per epoch: 1830 (<ipython-input-55-2bb0c577d71e>:29)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 15:14:27,584 - geometric-dl - INFO - <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc227730d00> (<ipython-input-55-2bb0c577d71e>:54)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 15:14:28,273 - geometric-dl - INFO - mean max of probabilities: tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) - temperature tensor([10.], device='cuda:0') (<ipython-input-55-2bb0c577d71e>:62)\u001b[0m\n",
      "\u001b[38;21m2021-06-11 15:14:29,734 - geometric-dl - INFO - iteration: 0 (<ipython-input-55-2bb0c577d71e>:85)\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f68779fb42dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         path = path)#,losstrain=losstrain,lossval=lossval)    \n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-2bb0c577d71e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, val_X)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0;31m# Compute the loss and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.8/site-packages/torch/profiler/profiler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mprev_action\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProfilerAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECORD_AND_SAVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trace_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trace_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.8/site-packages/torch/profiler/profiler.py\u001b[0m in \u001b[0;36m_stop_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stop_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.8/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkineto_activities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkineto_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mparsed_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_kineto_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkineto_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_profiler_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.8/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36mparse_kineto_results\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mfwd_thread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mcpu_memory_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_memory_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.8/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mfwd_thread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkineto_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mcpu_memory_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_memory_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "torch.manual_seed(14)\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    model_info_template_str = f'{run}_K={n_means}_epoch={num_epochs}_test={testsubjstr}_dec={decstr}'\n",
    "\n",
    "    checkpoint_path = str(Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}_runtime.h5'))\n",
    "    monitor_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = Path(ROOT_PATH, 'data')\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 12, 13, 14])\n",
    "    subj_list_valid = np.array([15])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(\n",
    "        train_set, \n",
    "        batch_size = run.batch_size, \n",
    "        shuffle = True, \n",
    "        num_workers = 15, \n",
    "        pin_memory=False, \n",
    "        drop_last=True)\n",
    "    \n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(\n",
    "        valid_set, \n",
    "        batch_size = run.batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = 15,\n",
    "        pin_memory=False, \n",
    "        drop_last=True)\n",
    "\n",
    "    path = str(Path(ROOT_PATH, 'runs', 'models', 'check15', 'model.pt'))\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    # checkpt = True\n",
    "    # temp = Tensor([10]) # check last value if necessary\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(\n",
    "        K=n_means, \n",
    "        num_features=n_means, \n",
    "        num_epochs=num_epochs, \n",
    "        learning_rate=run.lr, \n",
    "        start_temp=10, \n",
    "        min_temp=0.1, \n",
    "        tryout_limit=1, \n",
    "        input_dim=1344, \n",
    "        checkpt = checkpt, \n",
    "        callback=monitor_callback, \n",
    "        writer=writer, \n",
    "        path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}.pt'))\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(), Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}_params.pt'))\n",
    "    \n",
    "    print(np.sort(selector.get_indices().to('cpu')))\n",
    "    np.savetxt(Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}.txt'), np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    #torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "\n",
    "torch.save(model.state_dict(), Path(ROOT_PATH, 'runs', 'models', f'epoch={num_epochs}_net.pth'))\n",
    "model_file = open(Path(ROOT_PATH, 'runs', 'models', f'epoch={num_epochs}_net.bin'),'wb')\n",
    "pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "model_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_meas) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('./runs/textfiles/Run(lr=0.001, batch_size=256)K=500_epoch=2000_test15_decl2.txt')\n",
    "a = np.sort(a.astype(int))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 14\n",
    "testsubjstr = '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\"\"\"def pad_collate(batch):\n",
    "    xx = list(zip(*batch))\n",
    "    xx_pad = pad_sequence(torch.as_tensor(xx), batch_first=True, padding_value=0)\n",
    "    return xx_pad #, xlens\"\"\"\n",
    "\n",
    "#torch.manual_seed(14)\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './MUDI/data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 12, 13, 15])\n",
    "    subj_list_valid = np.array([14])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    \"\"\"### Allocate memory for losses\n",
    "    n_batch=0   # Count how many mini-batches of size mbatch we created\n",
    "    for j,signals in enumerate(train_gen):\n",
    "        n_batch = n_batch+1\n",
    "        signals = signals[:,:,ind_MUDI]\n",
    "        print(signals.size())\n",
    "    losstrain = np.zeros((num_epochs,n_batch)) + np.nan\n",
    "    \n",
    "    n_batch=0   # Count how many mini-batches of size mbatch we created\n",
    "    for j,signals in enumerate(valid_gen):\n",
    "        n_batch = n_batch+1\n",
    "    lossval = np.zeros((num_epochs,n_batch)) + np.nan\"\"\"\n",
    "    \n",
    "    path = './runs/models/check14/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = False\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "\n",
    "    #selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 13\n",
    "testsubjstr = '13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "\n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 12, 14, 15])\n",
    "    subj_list_valid = np.array([13])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    path = './runs/models/check13/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    #torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 12\n",
    "testsubjstr = '12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 13, 14, 15])\n",
    "    subj_list_valid = np.array([12])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    path = './runs/models/check12/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 11\n",
    "testsubjstr = '11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([12, 13, 14, 15])\n",
    "    subj_list_valid = np.array([11])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)  \n",
    "    \n",
    "    path = './runs/models/check11/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in RunBuilder.get_runs(params):\n",
    "    for trial in range(3):\n",
    "        logdir = \"./runs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_trial' + str(trial)\n",
    "\n",
    "        \"\"\"tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "        monitor_callback = keras.callbacks.ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_runtime'  + '_trial' + str(trial) + '.h5', monitor='val_loss', verbose=0, save_weights_only=True)\n",
    "\n",
    "        trainset = MRISelectorSubjDataset(root_dir='./data', dataf='data_.hdf5', headerf ='header_.csv',\n",
    "                                      subj_list=np.array([11, 12, 13, 14, 15]), batch_size=run.batch_size)\"\"\"\n",
    "        \n",
    "        tensorboard_callback = torch.utils.tensorboard(log_dir=logdir)\n",
    "        monitor_callback = pytorch_lightning.callbacks.ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "\n",
    "        root_dir = './data'\n",
    "        dataf = 'data_.hdf5'\n",
    "        headerf = 'header_.csv'\n",
    "        subj_list = np.array([11, 12, 13, 14, 15])\n",
    "\n",
    "        train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list)\n",
    "        train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True)\n",
    "        # for the validation dataset\n",
    "        #valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list)\n",
    "        #valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False)\n",
    "        \n",
    "        selector = ConcreteAutoencoderFeatureSelector(K=n_means, output_function=dec, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                      tryout_limit=5, input_dim=1344, callback=[tensorboard_callback, monitor_callback])\n",
    "\n",
    "        selector.fit(X=trainset)\n",
    "\n",
    "        model = selector.get_params()\n",
    "\n",
    "        model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_trial' + str(trial) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0d8aa0de02be0b131f97d6c1ce0bb8282df47d74804acd542e4e3d0f3fd66dc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
