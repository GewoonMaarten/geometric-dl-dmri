{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Autoencoders dMRI for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_path # Always import this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch import reshape as tshape\n",
    "from torch import matmul as tmat\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.env import DATA_PATH\n",
    "from utils.logger import logger, logging_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path().cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-24 11:08:15,424 - geometric-dl - INFO - torch version 1.9.0 (<ipython-input-4-a395a760577f>:1)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info('torch version %s', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-24 11:08:15,534 - geometric-dl - INFO - Current device: 0 (<ipython-input-5-bfdeb86c5565>:1)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:08:15,534 - geometric-dl - INFO - Device count: 1 (<ipython-input-5-bfdeb86c5565>:2)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:08:15,534 - geometric-dl - INFO - Is the GPU available? True (<ipython-input-5-bfdeb86c5565>:3)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:08:15,534 - geometric-dl - INFO - Using device: _CudaDeviceProperties(name='Quadro RTX 4000', major=7, minor=5, total_memory=8192MB, multi_processor_count=36) (<ipython-input-5-bfdeb86c5565>:7)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info('Current device: %s', torch.cuda.current_device())\n",
    "logger.info('Device count: %s', torch.cuda.device_count())\n",
    "logger.info('Is the GPU available? %s', torch.cuda.is_available())\n",
    "\n",
    "# # use gpu if available, else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info('Using device: %s', torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    lr = [.001],\n",
    "    batch_size = [256]\n",
    "#     batch_size = [64]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils.dataset import MRISelectorSubjDataset\n",
    "from utils.concrete import (\n",
    "    ConcreteAutoencoderFeatureSelector, \n",
    "    decoder_1l, \n",
    "    decoder_2l, \n",
    "    decoder_3l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_subject, test_subject, n_means=500, num_epochs=2000, decoder=decoder_1l):\n",
    "    strftime = \"%Y%m%d%H%M%S\"\n",
    "    writer = SummaryWriter(log_dir=Path(ROOT_PATH, 'runs', datetime.now().strftime(strftime)))\n",
    "\n",
    "    torch.manual_seed(14)\n",
    "\n",
    "    for run in RunBuilder.get_runs(params):\n",
    "        now = datetime.now()\n",
    "        model_info_template_str = f'{now:strftime}_{run}_K={n_means}_epoch={num_epochs}_test={test_subject[0]}_dec={decoder.__name__}'\n",
    "\n",
    "        checkpoint_path = str(Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}_runtime.h5'))\n",
    "        monitor_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=True)\n",
    "\n",
    "        root_dir = Path(ROOT_PATH, 'data')\n",
    "        dataf = 'data_.hdf5'\n",
    "        headerf = 'header_.csv'\n",
    "        subj_list_train = np.array(train_subject)\n",
    "        subj_list_valid = np.array(test_subject)\n",
    "\n",
    "        train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "        train_gen = DataLoader(\n",
    "            train_set, \n",
    "            batch_size = run.batch_size, \n",
    "            shuffle = True, \n",
    "            num_workers = 0, \n",
    "            pin_memory=True, \n",
    "            drop_last=True)\n",
    "\n",
    "        # for the validation dataset\n",
    "        valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "        valid_gen = DataLoader(\n",
    "            valid_set, \n",
    "            batch_size = run.batch_size, \n",
    "            shuffle = False, \n",
    "            num_workers = 0,\n",
    "            pin_memory=True, \n",
    "            drop_last=True)\n",
    "\n",
    "        # 1st time\n",
    "        checkpt = False\n",
    "        # Continue training\n",
    "        # checkpt = True\n",
    "        # temp = Tensor([10]) # check last value if necessary\n",
    "\n",
    "        selector = ConcreteAutoencoderFeatureSelector(\n",
    "            K=n_means,\n",
    "            decoder=decoder,\n",
    "            device=device,\n",
    "            num_features=n_means, \n",
    "            num_epochs=num_epochs, \n",
    "            learning_rate=run.lr, \n",
    "            start_temp=10, \n",
    "            min_temp=0.1, \n",
    "            tryout_limit=1, \n",
    "            input_dim=1344, \n",
    "            checkpt = checkpt, \n",
    "            callback=monitor_callback, \n",
    "            writer=writer, \n",
    "            path = ROOT_PATH)#,losstrain=losstrain,lossval=lossval)    \n",
    "\n",
    "        selector.fit(X=train_gen, val_X=valid_gen)\n",
    "\n",
    "        model = selector.get_params()\n",
    "        torch.save(model.state_dict(), Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}_params.pt'))\n",
    "\n",
    "        indices = selector.get_indices().to('cpu')\n",
    "        logger.info(np.sort(indices))\n",
    "        np.savetxt(Path(ROOT_PATH, 'runs', 'models', f'{model_info_template_str}.txt'), np.array(indices, dtype=int), fmt='%d')\n",
    "\n",
    "    torch.save(model.state_dict(), Path(ROOT_PATH, 'runs', 'models', f'epoch={num_epochs}_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2021-06-24 11:38:03,830 - geometric-dl - INFO - steps per epoch: 1830 (feature_selector.py:44)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:03,931 - geometric-dl - INFO - <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x000001DE90B3FA90> (feature_selector.py:73)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:03,939 - geometric-dl - INFO - epoch: 0/1 (feature_selector.py:84)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:03,941 - geometric-dl - INFO - mean max of probabilities: 0.00082959, temperature: 10.00000000 (feature_selector.py:85)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:03,981 - geometric-dl - INFO - iteration: 0 (feature_selector.py:109)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:06,253 - geometric-dl - INFO - iteration: 500 (feature_selector.py:109)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:08,473 - geometric-dl - INFO - iteration: 1000 (feature_selector.py:109)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:10,683 - geometric-dl - INFO - iteration: 1500 (feature_selector.py:109)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:13,175 - geometric-dl - INFO - loss: 0.0176 (feature_selector.py:146)\u001b[0m\n",
      "\u001b[38;21m2021-06-24 11:38:13,206 - geometric-dl - INFO - [   0   16   16   16   23   23   23   27   40   40   53   53   53   54\n",
      "   54   54   54   54   55   55   55   55   55   55   55   55   55   55\n",
      "   55   55   55   55   55   55   55   55   55   55   55   55   55   55\n",
      "   55   55   55   55   55   55   55   55   55   55   68   72   72   85\n",
      "  107  112  116  116  116  116  119  119  128  140  148  149  152  156\n",
      "  167  167  167  167  167  167  168  180  204  208  208  208  208  208\n",
      "  216  217  217  218  218  218  218  218  219  219  219  219  219  219\n",
      "  219  219  219  240  250  251  251  251  251  251  251  251  251  251\n",
      "  251  252  252  252  252  252  252  264  268  268  269  270  270  270\n",
      "  271  271  271  271  271  271  271  272  279  288  288  288  288  290\n",
      "  290  290  290  290  291  291  291  291  291  292  335  335  335  335\n",
      "  335  335  335  335  348  364  364  376  376  376  376  376  376  376\n",
      "  378  378  379  379  379  379  379  379  384  385  391  391  391  391\n",
      "  391  391  391  394  394  394  395  395  395  395  395  395  420  436\n",
      "  436  448  460  464  464  488  488  488  492  492  496  500  502  503\n",
      "  503  503  503  503  503  503  503  503  503  503  503  503  503  503\n",
      "  503  503  503  503  503  503  504  520  520  548  548  552  561  564\n",
      "  564  572  572  576  576  576  576  600  600  604  608  621  624  628\n",
      "  636  644  644  656  660  660  664  669  688  692  692  699  700  719\n",
      "  720  720  720  728  736  736  736  739  739  739  744  744  744  744\n",
      "  756  764  783  784  784  784  796  796  804  812  812  824  824  824\n",
      "  824  824  824  824  824  827  827  828  828  828  828  843  868  880\n",
      "  884  889  892  896  896  896  896  897  902  904  904  904  908  908\n",
      "  908  912  912  912  912  920  924  936  936  940  940  940  940  944\n",
      "  944  944  951  951  951  951  951  951  951  951  951  951  952  952\n",
      "  952  952  968  968  968  972  972  982  984  995  996  996  996  996\n",
      " 1000 1008 1008 1008 1008 1009 1016 1016 1018 1020 1024 1024 1024 1024\n",
      " 1024 1024 1024 1028 1048 1048 1048 1048 1048 1052 1052 1052 1052 1056\n",
      " 1056 1064 1064 1064 1065 1072 1084 1088 1088 1088 1092 1104 1104 1104\n",
      " 1108 1112 1116 1116 1116 1116 1116 1120 1125 1132 1136 1136 1140 1140\n",
      " 1140 1140 1148 1149 1152 1160 1160 1160 1160 1160 1160 1164 1168 1176\n",
      " 1176 1176 1176 1176 1179 1184 1184 1188 1188 1192 1192 1192 1192 1192\n",
      " 1192 1192 1200 1204 1204 1204 1204 1204 1207 1212 1214 1216 1224 1224\n",
      " 1224 1224 1232 1244 1244 1244 1244 1248 1248 1248 1252 1252 1260 1271\n",
      " 1272 1272 1276 1276 1276 1276 1276 1280 1280 1287 1300 1300 1300 1312\n",
      " 1312 1317 1324 1326 1328 1328 1332 1332 1332 1332] (<ipython-input-22-f1bff58e784e>:67)\u001b[0m\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_model([11, 12, 13, 14], [15], num_epochs=1, decoder=decoder_2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0c4b015ddd16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./runs/textfiles/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf'{run}'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'K='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_means\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_epoch='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_test'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtestsubjstr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_dec'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecstr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selector' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.sort(selector.get_indices().to('cpu')))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices().to('cpu'), dtype=int), fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('./runs/textfiles/Run(lr=0.001, batch_size=256)K=500_epoch=2000_test15_decl2.txt')\n",
    "a = np.sort(a.astype(int))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 14\n",
    "testsubjstr = '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\"\"\"def pad_collate(batch):\n",
    "    xx = list(zip(*batch))\n",
    "    xx_pad = pad_sequence(torch.as_tensor(xx), batch_first=True, padding_value=0)\n",
    "    return xx_pad #, xlens\"\"\"\n",
    "\n",
    "#torch.manual_seed(14)\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './MUDI/data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 12, 13, 15])\n",
    "    subj_list_valid = np.array([14])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    \"\"\"### Allocate memory for losses\n",
    "    n_batch=0   # Count how many mini-batches of size mbatch we created\n",
    "    for j,signals in enumerate(train_gen):\n",
    "        n_batch = n_batch+1\n",
    "        signals = signals[:,:,ind_MUDI]\n",
    "        print(signals.size())\n",
    "    losstrain = np.zeros((num_epochs,n_batch)) + np.nan\n",
    "    \n",
    "    n_batch=0   # Count how many mini-batches of size mbatch we created\n",
    "    for j,signals in enumerate(valid_gen):\n",
    "        n_batch = n_batch+1\n",
    "    lossval = np.zeros((num_epochs,n_batch)) + np.nan\"\"\"\n",
    "    \n",
    "    path = './runs/models/check14/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = False\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "\n",
    "    #selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 13\n",
    "testsubjstr = '13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "\n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 12, 14, 15])\n",
    "    subj_list_valid = np.array([13])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    path = './runs/models/check13/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    #torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 12\n",
    "testsubjstr = '12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([11, 13, 14, 15])\n",
    "    subj_list_valid = np.array([12])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    path = './runs/models/check12/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsubj = 11\n",
    "testsubjstr = '11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    monitor_callback = ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "    \n",
    "    root_dir = './data'\n",
    "    dataf = 'data_.hdf5'\n",
    "    headerf = 'header_.csv'\n",
    "    subj_list_train = np.array([12, 13, 14, 15])\n",
    "    subj_list_valid = np.array([11])\n",
    "    \n",
    "    train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_train)\n",
    "    train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, pin_memory=False, drop_last=True)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 4, pin_memory=False, collate_fn = pad_collate)\n",
    "    #train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True, num_workers = 0, pin_memory=False)#, collate_fn = pad_collate)\n",
    "    # for the validation dataset\n",
    "    valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list_valid)\n",
    "    valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False, pin_memory=False, drop_last=True)  \n",
    "    \n",
    "    path = './runs/models/check11/model.pt'\n",
    "    # 1st time\n",
    "    checkpt = False\n",
    "    # Continue training\n",
    "    checkpt = True\n",
    "    \n",
    "    selector = ConcreteAutoencoderFeatureSelector(K=n_means, num_features=n_means, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                  tryout_limit=5, input_dim=1344, checkpt = checkpt, callback=monitor_callback, writer=writer, path = path)#,losstrain=losstrain,lossval=lossval)    \n",
    "    \n",
    "    selector.fit(X=train_gen, val_X=valid_gen)\n",
    "    \n",
    "    model = selector.get_params()\n",
    "    \n",
    "    print(np.sort(selector.get_indices()))\n",
    "    np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d')\n",
    "    \n",
    "    #model.save('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.h5')\n",
    "    torch.save(model, './runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(),'./runs/models/params_' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.pt')\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join('./runs/models/','epoch{}_net.pth'.format(num_epochs)) )\n",
    "    model_file = open(os.path.join('./runs/models/','epoch{}_net.bin'.format(num_epochs)),'wb')\n",
    "    pk.dump(model,model_file,pk.HIGHEST_PROTOCOL)      \n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.sort(selector.get_indices()))\n",
    "np.savetxt('./runs/textfiles/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '.txt', np.array(selector.get_indices(), dtype=int), fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in RunBuilder.get_runs(params):\n",
    "    for trial in range(3):\n",
    "        logdir = \"./runs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_trial' + str(trial)\n",
    "\n",
    "        \"\"\"tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "        monitor_callback = keras.callbacks.ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_runtime'  + '_trial' + str(trial) + '.h5', monitor='val_loss', verbose=0, save_weights_only=True)\n",
    "\n",
    "        trainset = MRISelectorSubjDataset(root_dir='./data', dataf='data_.hdf5', headerf ='header_.csv',\n",
    "                                      subj_list=np.array([11, 12, 13, 14, 15]), batch_size=run.batch_size)\"\"\"\n",
    "        \n",
    "        tensorboard_callback = torch.utils.tensorboard(log_dir=logdir)\n",
    "        monitor_callback = pytorch_lightning.callbacks.ModelCheckpoint('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_test' + testsubjstr + '_dec' + decstr + '_runtime.h5', monitor='val_loss', verbose=True)\n",
    "\n",
    "        root_dir = './data'\n",
    "        dataf = 'data_.hdf5'\n",
    "        headerf = 'header_.csv'\n",
    "        subj_list = np.array([11, 12, 13, 14, 15])\n",
    "\n",
    "        train_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list)\n",
    "        train_gen = DataLoader(train_set, batch_size = run.batch_size, shuffle = True)\n",
    "        # for the validation dataset\n",
    "        #valid_set = MRISelectorSubjDataset(root_dir,dataf,headerf,subj_list)\n",
    "        #valid_gen = DataLoader(valid_set, batch_size = run.batch_size, shuffle = False)\n",
    "        \n",
    "        selector = ConcreteAutoencoderFeatureSelector(K=n_means, output_function=dec, num_epochs=num_epochs, learning_rate=run.lr, start_temp=10.0, min_temp=0.1, \n",
    "                                                      tryout_limit=5, input_dim=1344, callback=[tensorboard_callback, monitor_callback])\n",
    "\n",
    "        selector.fit(X=trainset)\n",
    "\n",
    "        model = selector.get_params()\n",
    "\n",
    "        model.save_weights('./runs/models/' + f'{run}' + 'K=' + str(n_means) + '_epoch=' + str(num_epochs) + '_testnone_dec' + decstr + '_trial' + str(trial) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0d8aa0de02be0b131f97d6c1ce0bb8282df47d74804acd542e4e3d0f3fd66dc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
