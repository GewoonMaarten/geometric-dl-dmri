{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc7dd7-02c8-4975-85b3-66f9e7cee8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from autoencoder.concrete_autoencoder import Decoder\n",
    "from autoencoder.dataset import MRIMemoryDataset, MRIMemorySHDataset\n",
    "from autoencoder.logger import logger, set_log_level\n",
    "from autoencoder.spherical.CG import real_clebsch_gordan_all\n",
    "from autoencoder.spherical.convolution import (\n",
    "    QuadraticNonLinearity,\n",
    "    S2Convolution,\n",
    "    SO3Convolution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00da21-3a0e-4c34-89b1-f8ae0d23f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f6a59-516e-4e97-b514-77cf6f7e3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available, else cpu\n",
    "has_cuda = torch.cuda.is_available()\n",
    "\n",
    "logger.info(\"Is the GPU available? %s\", has_cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if has_cuda else \"cpu\")\n",
    "if has_cuda:\n",
    "    logger.info(\"Current device: %s\", torch.cuda.current_device())\n",
    "    logger.info(\"Device count: %s\", torch.cuda.device_count())\n",
    "    logger.info(\"Using device: %s\", torch.cuda.get_device_properties(device))\n",
    "else:\n",
    "    logger.warning(\"No GPU dectected! Training will be slow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a32307-db80-4f53-9bf4-886ae44d7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalDecoder(pl.LightningModule):\n",
    "    def __init__(self, *, learning_rate: float = 1e-4, profiler=None) -> None:\n",
    "        super(SphericalDecoder, self).__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        L = [2, 2, 0]\n",
    "        CG_r, CG_l = real_clebsch_gordan_all(L[0], L[1], device=\"cuda\")\n",
    "\n",
    "        self.spherical = torch.nn.Sequential(\n",
    "            S2Convolution(28, 3, L[0], 5, 8, profiler=profiler),\n",
    "            QuadraticNonLinearity(L[0], L[1], CG_r, CG_l),\n",
    "            SO3Convolution(28, 3, L[1], 8, 16, profiler=profiler),\n",
    "            QuadraticNonLinearity(L[1], L[2], CG_r, CG_l),\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(2688, 1344)\n",
    "\n",
    "    def forward(self, x: dict[int, torch.Tensor]) -> torch.Tensor:\n",
    "        _, features = self.spherical(x)\n",
    "        return self.linear(features)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Adam:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: dict[str, torch.Tensor],\n",
    "        batch_idx: int,\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def _shared_eval(\n",
    "        self, batch: torch.Tensor, batch_idx: int, prefix: str\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Calculate the loss for a batch.\n",
    "\n",
    "        Args:\n",
    "            batch (torch.Tensor): batch data.\n",
    "            batch_idx (int): batch id.\n",
    "            prefix (str): prefix for logging.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: calculated loss.\n",
    "        \"\"\"\n",
    "        data, target = batch[\"data\"], batch[\"target\"]\n",
    "\n",
    "        decoded = self.forward(data)\n",
    "        loss = F.mse_loss(decoded, target)\n",
    "\n",
    "        self.log(f\"{prefix}_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e3614-0cf0-4015-8962-49aed9fd1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_features = np.loadtxt(\"latent_features.txt\", dtype=int)\n",
    "\n",
    "batch_size = 256\n",
    "train_subjects = [11, 12, 13, 14]\n",
    "validate_subjects = [15]\n",
    "\n",
    "train_dataset = MRIMemorySHDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    train_subjects,\n",
    "    include=latent_features,\n",
    "    l_max=2,\n",
    ")\n",
    "\n",
    "validate_dataset = MRIMemorySHDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    validate_subjects,\n",
    "    include=latent_features,\n",
    "    l_max=2,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=6,\n",
    ")\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c65b82-2dcd-455f-9adb-500ebadb5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"spherical_decoder\"\n",
    "\n",
    "# mlflow.set_tracking_uri(os.environ[\"MLFLOW_ENDPOINT_URL\"])\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "profiler = pl.profiler.AdvancedProfiler(filename=\"test_sh.txt\")\n",
    "profiler = None\n",
    "\n",
    "model = SphericalDecoder(profiler=profiler)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=-1,\n",
    "    profiler=profiler,\n",
    "    max_epochs=2000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\"),\n",
    "        ModelCheckpoint(monitor=\"val_loss\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, train_dataloader, validate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e305fc-89cc-45d0-8dea-d9a165ffc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(pl.LightningModule):\n",
    "    def __init__(self, *, learning_rate: float = 1e-3, profiler=None) -> None:\n",
    "        super(LinearDecoder, self).__init__()\n",
    "\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        self._linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(500, 800),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(800, 1344),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self._linear(x)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Adam:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self._learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def _shared_eval(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int, prefix: str\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Calculate the loss for a batch.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple[torch.Tensor, torch.Tensor]): batch data, first element in the tuple is the target data, and the second element in the input data.\n",
    "            batch_idx (int): batch id.\n",
    "            prefix (str): prefix for logging.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: calculated loss.\n",
    "        \"\"\"\n",
    "        target, data = batch\n",
    "\n",
    "        decoded = self.forward(data)\n",
    "        loss = F.mse_loss(decoded, target)\n",
    "\n",
    "        self.log(f\"{prefix}_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fe942-e3ee-4ad3-8155-c4bb2253341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_features = np.loadtxt(\"latent_features.txt\", dtype=int)\n",
    "\n",
    "batch_size = 256\n",
    "train_subjects = [11, 12, 13, 14]\n",
    "validate_subjects = [15]\n",
    "\n",
    "train_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\", train_subjects, include=latent_features, do_store_in_gpu=False\n",
    ")\n",
    "\n",
    "validate_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    validate_subjects,\n",
    "    include=latent_features,\n",
    "    do_store_in_gpu=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, pin_memory=True, batch_size=batch_size, num_workers=6\n",
    ")\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad524-e9e5-41e5-a315-46031a5003f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"linear_decoder\"\n",
    "\n",
    "# mlflow.set_tracking_uri(os.environ[\"MLFLOW_ENDPOINT_URL\"])\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "model = LinearDecoder()\n",
    "trainer = pl.Trainer(\n",
    "    gpus=-1,\n",
    "    max_epochs=2000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\"),\n",
    "        ModelCheckpoint(monitor=\"val_loss\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, train_dataloader, validate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f63166-4adf-4bff-b06e-c2ae0761c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [2, 2, 0]\n",
    "CG_r, CG_l = real_clebsch_gordan_all(L[0], L[1], device=\"cpu\")\n",
    "\n",
    "s2_conv = S2Convolution(28, 3, L[0], L[1], 5, 8, CG_r, CG_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8e963-82ce-41b4-a58b-506842377c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = dict()\n",
    "rh[0] = torch.rand((256, 28, 3, 5, 1, 5))\n",
    "rh[2] = torch.rand((256, 28, 3, 5, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507321b4-12a0-4651-8be2-648293ba2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0, 2 + 1, 2):\n",
    "    # rh_n_l_t = torch.transpose(rh[l], 2, 0)\n",
    "    rh_n_l_p = torch.pow(rh[l], 2)\n",
    "    rh_n_l_s = torch.sum(rh_n_l_p, (5, 4))\n",
    "\n",
    "    # else:\n",
    "    x = torch.cat((x, torch.flatten(rh_n_l_s, start_dim=1)), dim=1)\n",
    "    print(rh_n_l_p.shape, rh_n_l_s.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc9202-2834-4f17-bf52-de4a4fb76a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((165, 28, 3, 5, 5))\n",
    "w = torch.rand((28, 3, 5, 8, 5))\n",
    "\n",
    "# torch.einsum(\"nabil, abiok->nabolk\", x, w) + torch.zeros(1, 28, 3, 8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcf5b9-f5b6-430a-84e9-7ff6201da39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.einsum(\"nabil, abiok->nabolk\", x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09582d6-cd25-4b08-9aed-787f4cae82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "f + torch.zeros(1, 28, 3, 8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cf5eb-4e9e-442e-a7fa-e7218c3daadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105db442-eba9-46f3-8a94-f5594f8d898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((x,), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a83d99-93bf-464b-852e-30eb49be15bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
