{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cc7dd7-02c8-4975-85b3-66f9e7cee8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from autoencoder.concrete_autoencoder import Decoder\n",
    "from autoencoder.dataset import MRIMemoryDataset, SphericalTransformer\n",
    "from autoencoder.logger import logger, set_log_level\n",
    "from autoencoder.spherical.convolution import (\n",
    "    QuadraticNonLinearity,\n",
    "    S2Convolution,\n",
    "    SO3Convolution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f6a59-516e-4e97-b514-77cf6f7e3774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m2022-01-10 16:26:33,314 - MUDI - INFO - Is the GPU available? True (4000071966.py:6)\u001b[0m\n",
      "\u001b[38;21m2022-01-10 16:26:33,317 - MUDI - INFO - Current device: 0 (4000071966.py:10)\u001b[0m\n",
      "\u001b[38;21m2022-01-10 16:26:33,319 - MUDI - INFO - Device count: 1 (4000071966.py:11)\u001b[0m\n",
      "\u001b[38;21m2022-01-10 16:26:33,320 - MUDI - INFO - Using device: _CudaDeviceProperties(name='NVIDIA GeForce GTX 1080', major=6, minor=1, total_memory=8116MB, multi_processor_count=20) (4000071966.py:12)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "set_log_level(10)\n",
    "\n",
    "# use gpu if available, else cpu\n",
    "has_cuda = torch.cuda.is_available()\n",
    "\n",
    "logger.info(\"Is the GPU available? %s\", has_cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if has_cuda else \"cpu\")\n",
    "if has_cuda:\n",
    "    logger.info(\"Current device: %s\", torch.cuda.current_device())\n",
    "    logger.info(\"Device count: %s\", torch.cuda.device_count())\n",
    "    logger.info(\"Using device: %s\", torch.cuda.get_device_properties(device))\n",
    "else:\n",
    "    logger.warning(\"No GPU dectected! Training will be slow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a32307-db80-4f53-9bf4-886ae44d7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalDecoder(pl.LightningModule):\n",
    "    def __init__(self, *, learning_rate: float = 1e-4, profiler=None) -> None:\n",
    "        super(SphericalDecoder, self).__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        L = [2, 2, 0]\n",
    "        self.spherical = torch.nn.Sequential(\n",
    "            S2Convolution(28, 3, L[0], 5, 8),\n",
    "            QuadraticNonLinearity(L[0], L[1]),\n",
    "            SO3Convolution(28, 3, L[1], 8, 16),\n",
    "            QuadraticNonLinearity(L[1], L[2]),\n",
    "        )\n",
    "        # self.linear = torch.nn.Linear(2688, 1344)\n",
    "\n",
    "    def forward(self, x: dict[int, torch.Tensor]) -> torch.Tensor:\n",
    "        _, features = self.spherical(x)\n",
    "        return features\n",
    "        # return self.linear(features)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Adam:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: dict[str, torch.Tensor],\n",
    "        batch_idx: int,\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def _shared_eval(\n",
    "        self, batch: torch.Tensor, batch_idx: int, prefix: str\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Calculate the loss for a batch.\n",
    "\n",
    "        Args:\n",
    "            batch (torch.Tensor): batch data.\n",
    "            batch_idx (int): batch id.\n",
    "            prefix (str): prefix for logging.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: calculated loss.\n",
    "        \"\"\"\n",
    "        data, target = batch[\"data\"], batch[\"target\"]\n",
    "\n",
    "        decoded = self.forward(data)\n",
    "        loss = F.mse_loss(torch.randn(3, 5, requires_grad=True), torch.randn(3, 5))\n",
    "\n",
    "        self.log(f\"{prefix}_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5e3614-0cf0-4015-8962-49aed9fd1413",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have cuda DeviceType, but got tensor with cpu DeviceType (while checking arguments for einsum():)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56729/116544168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidate_subjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m train_dataset = MRIMemoryDataset(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"../data/data.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_subjects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/School/uu/thesis/geometric-dl-dmri/src/autoencoder/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_file_path, subject_list, exclude, include, do_store_in_gpu, transform)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/School/uu/thesis/geometric-dl-dmri/src/autoencoder/dataset.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0my_inv_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_inv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_scheme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0msh_coefficient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"np,lp->nl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_inv_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Extract even covariants.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mudi/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have cuda DeviceType, but got tensor with cpu DeviceType (while checking arguments for einsum():)"
     ]
    }
   ],
   "source": [
    "latent_features = np.loadtxt(\"latent_features.txt\", dtype=int)\n",
    "\n",
    "batch_size = 256\n",
    "train_subjects = [11, 12, 13, 14]\n",
    "validate_subjects = [15]\n",
    "\n",
    "train_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    train_subjects,\n",
    "    include=latent_features,\n",
    "    transform=SphericalTransformer(l_max=2),\n",
    "    do_store_in_gpu=False\n",
    ")\n",
    "\n",
    "validate_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    validate_subjects,\n",
    "    include=latent_features,\n",
    "    transform=SphericalTransformer(l_max=2),\n",
    "    do_store_in_gpu=False\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=6,\n",
    ")\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c65b82-2dcd-455f-9adb-500ebadb5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"spherical_decoder\"\n",
    "\n",
    "# mlflow.set_tracking_uri(os.environ[\"MLFLOW_ENDPOINT_URL\"])\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "profiler = pl.profiler.AdvancedProfiler(filename=\"test_sh.txt\")\n",
    "profiler = None\n",
    "\n",
    "model = SphericalDecoder(profiler=profiler)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=-1,\n",
    "    profiler=profiler,\n",
    "    max_epochs=2000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\"),\n",
    "        ModelCheckpoint(monitor=\"val_loss\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, train_dataloader, validate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e305fc-89cc-45d0-8dea-d9a165ffc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(pl.LightningModule):\n",
    "    def __init__(self, *, learning_rate: float = 1e-3, profiler=None) -> None:\n",
    "        super(LinearDecoder, self).__init__()\n",
    "\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        self._linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(500, 800),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(800, 1344),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self._linear(x)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Adam:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self._learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        return self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def _shared_eval(\n",
    "        self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int, prefix: str\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Calculate the loss for a batch.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple[torch.Tensor, torch.Tensor]): batch data, first element in the tuple is the target data, and the second element in the input data.\n",
    "            batch_idx (int): batch id.\n",
    "            prefix (str): prefix for logging.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: calculated loss.\n",
    "        \"\"\"\n",
    "        target, data = batch\n",
    "\n",
    "        decoded = self.forward(data)\n",
    "        loss = F.mse_loss(decoded, target)\n",
    "\n",
    "        self.log(f\"{prefix}_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fe942-e3ee-4ad3-8155-c4bb2253341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_features = np.loadtxt(\"latent_features.txt\", dtype=int)\n",
    "\n",
    "batch_size = 256\n",
    "train_subjects = [11, 12, 13, 14]\n",
    "validate_subjects = [15]\n",
    "\n",
    "train_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\", train_subjects, include=latent_features, do_store_in_gpu=False\n",
    ")\n",
    "\n",
    "validate_dataset = MRIMemoryDataset(\n",
    "    \"../data/data.hdf5\",\n",
    "    validate_subjects,\n",
    "    include=latent_features,\n",
    "    do_store_in_gpu=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, pin_memory=True, batch_size=batch_size, num_workers=6\n",
    ")\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad524-e9e5-41e5-a315-46031a5003f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"linear_decoder\"\n",
    "\n",
    "# mlflow.set_tracking_uri(os.environ[\"MLFLOW_ENDPOINT_URL\"])\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "model = LinearDecoder()\n",
    "trainer = pl.Trainer(\n",
    "    gpus=-1,\n",
    "    max_epochs=2000,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\"),\n",
    "        ModelCheckpoint(monitor=\"val_loss\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, train_dataloader, validate_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
