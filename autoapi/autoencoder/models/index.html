
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>autoencoder.models &#8212; Concrete Autoencoder  documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/thebelab.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="../../../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Concrete Autoencoder  documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../index.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       autoencoder
      </span>
     </code>
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../spherical/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         autoencoder.spherical
        </span>
       </code>
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../spherical/convolution/index.html">
         <code class="xref py py-mod docutils literal notranslate">
          <span class="pre">
           autoencoder.spherical.convolution
          </span>
         </code>
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../spherical/harmonics/index.html">
         <code class="xref py py-mod docutils literal notranslate">
          <span class="pre">
           autoencoder.spherical.harmonics
          </span>
         </code>
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../spherical/transform/index.html">
         <code class="xref py py-mod docutils literal notranslate">
          <span class="pre">
           autoencoder.spherical.transform
          </span>
         </code>
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../__main__/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         autoencoder.__main__
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../datasets/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         autoencoder.datasets
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../logger/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         autoencoder.logger
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         autoencoder.models
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/autoapi/autoencoder/models/index.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-contents">
   Module Contents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classes">
     Classes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functions">
     Functions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.init_weights_orthogonal">
       init_weights_orthogonal
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.Encoder">
       Encoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.latent_features">
         latent_features
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.forward">
         forward
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.update_temp">
         update_temp
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.calc_mean_max">
         calc_mean_max
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.regularization">
         regularization
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.Decoder">
       Decoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Decoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder">
       ConcreteAutoencoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.forward">
         forward
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.configure_optimizers">
         configure_optimizers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.training_step">
         training_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.validation_step">
         validation_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.test_step">
         test_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.on_train_epoch_start">
         on_train_epoch_start
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.on_epoch_end">
         on_epoch_end
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder._shared_eval">
         _shared_eval
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder">
       BaseDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.configure_optimizers">
         configure_optimizers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.training_step">
         training_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.validation_step">
         validation_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.test_step">
         test_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder._shared_eval">
         _shared_eval
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.FCNDecoder">
       FCNDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.FCNDecoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.SphericalDecoder">
       SphericalDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.SphericalDecoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>autoencoder.models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-contents">
   Module Contents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classes">
     Classes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functions">
     Functions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.init_weights_orthogonal">
       init_weights_orthogonal
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.Encoder">
       Encoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.latent_features">
         latent_features
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.forward">
         forward
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.update_temp">
         update_temp
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.calc_mean_max">
         calc_mean_max
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Encoder.regularization">
         regularization
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.Decoder">
       Decoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.Decoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder">
       ConcreteAutoencoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.forward">
         forward
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.configure_optimizers">
         configure_optimizers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.training_step">
         training_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.validation_step">
         validation_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.test_step">
         test_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.on_train_epoch_start">
         on_train_epoch_start
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder.on_epoch_end">
         on_epoch_end
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.ConcreteAutoencoder._shared_eval">
         _shared_eval
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder">
       BaseDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.configure_optimizers">
         configure_optimizers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.training_step">
         training_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.validation_step">
         validation_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder.test_step">
         test_step
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.BaseDecoder._shared_eval">
         _shared_eval
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.FCNDecoder">
       FCNDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.FCNDecoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autoencoder.models.SphericalDecoder">
       SphericalDecoder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#autoencoder.models.SphericalDecoder.forward">
         forward
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="module-autoencoder.models">
<span id="autoencoder-models"></span><h1><a class="reference internal" href="#module-autoencoder.models" title="autoencoder.models"><code class="xref py py-mod docutils literal notranslate"><span class="pre">autoencoder.models</span></code></a><a class="headerlink" href="#module-autoencoder.models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#autoencoder.models.Encoder" title="autoencoder.models.Encoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Encoder</span></code></a></p></td>
<td><p>Feature selection encoder. Implemented according to [_Concrete Autoencoders for Differentiable Feature Selection and <a href="#id1"><span class="problematic" id="id2">Reconstruction_</span></a>](<a class="reference external" href="https://arxiv.org/abs/1901.09346">https://arxiv.org/abs/1901.09346</a>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#autoencoder.models.Decoder" title="autoencoder.models.Decoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Decoder</span></code></a></p></td>
<td><p>Standard decoder. It generates a network from <cite>input_size</cite> to <cite>output_size</cite>. The layers are generates as</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#autoencoder.models.ConcreteAutoencoder" title="autoencoder.models.ConcreteAutoencoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConcreteAutoencoder</span></code></a></p></td>
<td><p>Trains a concrete autoencoder. Implemented according to [_Concrete Autoencoders for Differentiable Feature Selection and <a href="#id3"><span class="problematic" id="id4">Reconstruction_</span></a>](<a class="reference external" href="https://arxiv.org/abs/1901.09346">https://arxiv.org/abs/1901.09346</a>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#autoencoder.models.BaseDecoder" title="autoencoder.models.BaseDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseDecoder</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#autoencoder.models.FCNDecoder" title="autoencoder.models.FCNDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FCNDecoder</span></code></a></p></td>
<td><p>Fully Connected Network decoder</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#autoencoder.models.SphericalDecoder" title="autoencoder.models.SphericalDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SphericalDecoder</span></code></a></p></td>
<td><p>Spherical decoder based on: &quot;A Spherical Convolutional Neural Network for White Matter Structure Imaging via dMRI&quot; by Sedlar et al.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#autoencoder.models.init_weights_orthogonal" title="autoencoder.models.init_weights_orthogonal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">init_weights_orthogonal</span></code></a>(m)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.models.init_weights_orthogonal">
<span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">init_weights_orthogonal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.init_weights_orthogonal" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.Encoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">Encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Feature selection encoder. Implemented according to [_Concrete Autoencoders for Differentiable Feature Selection and <a href="#id5"><span class="problematic" id="id6">Reconstruction_</span></a>](<a class="reference external" href="https://arxiv.org/abs/1901.09346">https://arxiv.org/abs/1901.09346</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – size of the input layer. Should be the same as the <cite>output_size</cite> of the decoder.</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – size of the latent layer. Should be the same as the <cite>input_size</cite> of the decoder.</p></li>
<li><p><strong>max_temp</strong> (<em>float</em><em>, </em><em>optional</em>) – maximum temperature for Gumble Softmax. Defaults to 10.0.</p></li>
<li><p><strong>min_temp</strong> (<em>float</em><em>, </em><em>optional</em>) – minimum temperature for Gumble Softmax. Defaults to 0.1.</p></li>
<li><p><strong>reg_threshold</strong> (<em>float</em><em>, </em><em>optional</em>) – regularization threshold. The encoder will be penalized when the sum of</p></li>
<li><p><strong>0.3.</strong> (<em>probabilities for a selection neuron exceed this threshold. Defaults to</em>) – </p></li>
<li><p><strong>reg_eps</strong> (<em>float</em><em>, </em><em>optional</em>) – regularization epsilon. Minimum value for the clamped softmax function in</p></li>
<li><p><strong>1e-10.</strong> (<em>regularization term. Defaults to</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Encoder.latent_features">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">latent_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder.latent_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Encoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the trained encoder to make inferences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – input data. Should be the same size as the encoder input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder output of size <cite>output_size</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Encoder.update_temp">
<span class="sig-name descname"><span class="pre">update_temp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder.update_temp" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Encoder.calc_mean_max">
<span class="sig-name descname"><span class="pre">calc_mean_max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder.calc_mean_max" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Encoder.regularization">
<span class="sig-name descname"><span class="pre">regularization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Encoder.regularization" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularization term according to <a class="reference external" href="https://homes.esat.kuleuven.be/~abertran/reports/TS_JNE_2021.pdf">https://homes.esat.kuleuven.be/~abertran/reports/TS_JNE_2021.pdf</a>. The sum of
probabilities for a selection neuron is penalized if its larger than the threshold value. The returned value is
summed with the loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.Decoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">Decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_hidden_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Standard decoder. It generates a network from <cite>input_size</cite> to <cite>output_size</cite>. The layers are generates as
follows:
<code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">import</span> <span class="pre">numpy</span> <span class="pre">as</span> <span class="pre">np</span>
<span class="pre">step_size</span> <span class="pre">=</span> <span class="pre">abs(output_size</span> <span class="pre">-</span> <span class="pre">input_size)</span> <span class="pre">//</span> <span class="pre">n_hidden_layers</span>
<span class="pre">layer_sizes</span> <span class="pre">=</span> <span class="pre">np.arange(input_size,</span> <span class="pre">output_size,</span> <span class="pre">step_size)</span>
<span class="pre">`</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – size of the latent layer. Should be the same as the <cite>output_size</cite> of the encoder.</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – size of the output layer. Should be the same as <cite>input_size</cite> of the encoder.</p></li>
<li><p><strong>n_hidden_layers</strong> (<em>int</em>) – number of hidden layers. If 0 then the input will be directly connected to the</p></li>
<li><p><strong>output.</strong> – </p></li>
<li><p><strong>negative_slope</strong> (<em>float</em><em>, </em><em>optional</em>) – negative slope for the Leaky ReLu activation layer. Defaults to 0.2.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.Decoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the trained decoder to make inferences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – input data. Should be the same size as the decoder input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>decoder output of size <cite>output_size</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">ConcreteAutoencoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_output_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1344</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_hidden_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pytorch_lightning.LightningModule</span></code></p>
<p>Trains a concrete autoencoder. Implemented according to [_Concrete Autoencoders for Differentiable Feature Selection and <a href="#id7"><span class="problematic" id="id8">Reconstruction_</span></a>](<a class="reference external" href="https://arxiv.org/abs/1901.09346">https://arxiv.org/abs/1901.09346</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_output_size</strong> (<em>int</em>) – size of the input and output layer.</p></li>
<li><p><strong>latent_size</strong> (<em>int</em>) – size of the latent layer.</p></li>
<li><p><strong>decoder_hidden_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – number of hidden layers for the decoder. Defaults to 2.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – learning rate for the optimizer. Defaults to 1e-3.</p></li>
<li><p><strong>max_temp</strong> (<em>float</em><em>, </em><em>optional</em>) – maximum temperature for Gumble Softmax. Defaults to 10.0.</p></li>
<li><p><strong>min_temp</strong> (<em>float</em><em>, </em><em>optional</em>) – minimum temperature for Gumble Softmax. Defaults to 0.1.</p></li>
<li><p><strong>reg_lambda</strong> (<em>float</em><em>, </em><em>optional</em>) – how much weight to apply to the regularization term. If the value is 0.0 then no regularization will be applied. Defaults to 0.0.</p></li>
<li><p><strong>reg_threshold</strong> (<em>float</em><em>, </em><em>optional</em>) – regularization threshold. The encoder will be penalized when the sum of probabilities for a selection neuron exceed this threshold. Defaults to 1.0.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the trained autoencoder to make inferences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – input data. Should be the same size as encoder input.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(encoder output, decoder output)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.optim.Adam</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.training_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.test_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
<li><p><strong>dataloader_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.on_train_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.ConcreteAutoencoder._shared_eval">
<span class="sig-name descname"><span class="pre">_shared_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.ConcreteAutoencoder._shared_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the loss for a batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – batch data.</p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – batch id.</p></li>
<li><p><strong>prefix</strong> (<em>str</em>) – prefix for logging.</p></li>
<li><p><strong>dataloader_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>calculated loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">BaseDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pytorch_lightning.LightningModule</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.optim.Adam</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder.training_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>torch.Tensor</em><em>]</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder.test_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – </p></li>
<li><p><strong>dataloader_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.BaseDecoder._shared_eval">
<span class="sig-name descname"><span class="pre">_shared_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.BaseDecoder._shared_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the loss for a batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – batch data.</p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – batch id.</p></li>
<li><p><strong>prefix</strong> (<em>str</em>) – prefix for logging.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>calculated loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.FCNDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">FCNDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.FCNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#autoencoder.models.BaseDecoder" title="autoencoder.models.BaseDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseDecoder</span></code></a></p>
<p>Fully Connected Network decoder</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – input size of the network</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – output size of the network</p></li>
<li><p><strong>hidden_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – number of hidden layers. Defaults to 2.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – learning rate. Defaults to 1e-3.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.FCNDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.FCNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="autoencoder.models.SphericalDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">autoencoder.models.</span></span><span class="sig-name descname"><span class="pre">SphericalDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_ti</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_te</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_layer_input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_layer_output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shells</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">L</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.SphericalDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#autoencoder.models.BaseDecoder" title="autoencoder.models.BaseDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseDecoder</span></code></a></p>
<p>Spherical decoder based on: “A Spherical Convolutional Neural Network for White Matter Structure Imaging via dMRI” by Sedlar et al.</p>
<p>paper: <a class="reference external" href="https://rdcu.be/cFiOY">https://rdcu.be/cFiOY</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_ti</strong> (<em>int</em>) – number of unique TI values.</p></li>
<li><p><strong>n_te</strong> (<em>int</em>) – number of unique TE values.</p></li>
<li><p><strong>linear_layer_input_size</strong> (<em>int</em>) – size of the input for the linear layer.</p></li>
<li><p><strong>linear_layer_output_size</strong> (<em>int</em>) – size of the output for the linear layer.</p></li>
<li><p><strong>n_shells</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – number of b-value shells. List size determines number of convolutions. List size
should be the same as L.</p></li>
<li><p><strong>L</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – degree of spherical harmonic. List size determines number of convolutions. List size should
be the same as n_shells.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – learning rate. Defaults to 1e-3.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="autoencoder.models.SphericalDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.models.SphericalDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>torch.Tensor</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Maarten de Klerk<br/>
    
        &copy; Copyright 2022, Maarten de Klerk.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>